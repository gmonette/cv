<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="cv">
<title>Extending the cv package • cv</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Extending the cv package">
<meta property="og:description" content="cv">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-light navbar-expand-lg bg-light"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">cv</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="Released version">1.1.0</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../articles/cv.html">Get started</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="active nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-articles">Articles</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-articles">
    <a class="dropdown-item" href="../articles/cv-extend.html">Extending the cv package</a>
  </div>
</li>
<li class="nav-item">
  <a class="nav-link" href="../news/index.html">Changelog</a>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav">
<li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/gmonette/cv/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="" class="logo" alt=""><h1>Extending the cv package</h1>
                        <h4 data-toc-skip class="author">John Fox and
Georges Monette</h4>
            
            <h4 data-toc-skip class="date">2024-01-18</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/gmonette/cv/blob/HEAD/vignettes/cv-extend.Rmd" class="external-link"><code>vignettes/cv-extend.Rmd</code></a></small>
      <div class="d-none name"><code>cv-extend.Rmd</code></div>
    </div>

    
    
<p>The <strong>cv</strong> package is designed to be extensible in
several directions. In this vignette, we discuss three kinds of
extensions, ordered by increasing general complexity: (1) adding a
cross-validation cost criterion; (2) adding a model class that’s not
directly accommodated by the <code><a href="../reference/cv.html">cv()</a></code> default method or by
another directly inherited method, with separate consideration of
mixed-effects models; and (3) adding a new model-selection procedure
suitable for use with <code>selectModel()</code>.</p>
<div class="section level2">
<h2 id="adding-a-cost-criterion">Adding a cost criterion<a class="anchor" aria-label="anchor" href="#adding-a-cost-criterion"></a>
</h2>
<p>A cost criterion suitable for use with <code><a href="../reference/cv.html">cv()</a></code> or
<code><a href="../reference/cvSelect.html">cvSelect()</a></code> should take two arguments, <code>y</code> (the
observed response vector) and <code>yhat</code> (a vector of fitted or
predicted response values), and return a numeric index of lack of fit.
The <strong>cv</strong> package supplies several such criteria:
<code>mse(y, yhat)</code>, which returns the mean-squared prediction
error for a numeric response; <code>rmse(y, yhat)</code>, which returns
the (square-)root mean-squared error; <code>medAbsErr(y, yhat)</code>,
which returns the median absolute error; and
<code>BayesRule(y, yhat)</code> (and its non-error-checking version,
<code>BayesRule2(y, yhat))</code>, suitable for use with a binary
regression model, where <code>y</code> is the binary response coded
<code>0</code> for a “failure” or <code>1</code> for a “success”; where
<code>yhat</code> is the predicted probability of success; and where the
proportion of <em>incorrectly</em> classified cases is returned.</p>
<p>To illustrate using a different prediction cost criterion, we’ll base
a cost criterion on the area under the receiver operating characteristic
(“ROC”) curve for a logistic regression. The ROC curve is a graphical
representation of the classification power of a binary regression model,
and the area under the ROC curve (“AUC”), which varies from 0 to 1, is a
common summary measure based on the ROC <span class="citation">(see
"Receiver operating characteristic", 2023)</span>. The
<strong>Metrics</strong> package <span class="citation">(Hamner &amp;
Frasco, 2018)</span> includes a variety of measures useful for model
selection, including an <code>auc()</code> function. We convert the AUC
into a cost measure by taking its complement:</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">AUCcomp</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">y</span>, <span class="va">yhat</span><span class="op">)</span> <span class="fl">1</span> <span class="op">-</span> <span class="fu">Metrics</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/Metrics/man/auc.html" class="external-link">auc</a></span><span class="op">(</span><span class="va">y</span>, <span class="va">yhat</span><span class="op">)</span></span></code></pre></div>
<p>We then apply <code>AUCcomp()</code> to the the Mroz logistic
regression discussed in the main <strong>cv</strong> package vignette,
which we reproduce here, using the <code>Mroz</code> data frame from the
<strong>carData</strong> package <span class="citation">(Fox &amp;
Weisberg, 2019)</span>:</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/data.html" class="external-link">data</a></span><span class="op">(</span><span class="st">"Mroz"</span>, package<span class="op">=</span><span class="st">"carData"</span><span class="op">)</span></span>
<span><span class="va">m.mroz</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/glm.html" class="external-link">glm</a></span><span class="op">(</span><span class="va">lfp</span> <span class="op">~</span> <span class="va">.</span>, data<span class="op">=</span><span class="va">Mroz</span>, family<span class="op">=</span><span class="va">binomial</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">m.mroz</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:</span></span>
<span><span class="co">#&gt; glm(formula = lfp ~ ., family = binomial, data = Mroz)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Coefficients:</span></span>
<span><span class="co">#&gt;             Estimate Std. Error z value Pr(&gt;|z|)    </span></span>
<span><span class="co">#&gt; (Intercept)  3.18214    0.64438    4.94  7.9e-07 ***</span></span>
<span><span class="co">#&gt; k5          -1.46291    0.19700   -7.43  1.1e-13 ***</span></span>
<span><span class="co">#&gt; k618        -0.06457    0.06800   -0.95  0.34234    </span></span>
<span><span class="co">#&gt; age         -0.06287    0.01278   -4.92  8.7e-07 ***</span></span>
<span><span class="co">#&gt; wcyes        0.80727    0.22998    3.51  0.00045 ***</span></span>
<span><span class="co">#&gt; hcyes        0.11173    0.20604    0.54  0.58762    </span></span>
<span><span class="co">#&gt; lwg          0.60469    0.15082    4.01  6.1e-05 ***</span></span>
<span><span class="co">#&gt; inc         -0.03445    0.00821   -4.20  2.7e-05 ***</span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; (Dispersion parameter for binomial family taken to be 1)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;     Null deviance: 1029.75  on 752  degrees of freedom</span></span>
<span><span class="co">#&gt; Residual deviance:  905.27  on 745  degrees of freedom</span></span>
<span><span class="co">#&gt; AIC: 921.3</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Number of Fisher Scoring iterations: 4</span></span>
<span></span>
<span><span class="fu">AUCcomp</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/with.html" class="external-link">with</a></span><span class="op">(</span><span class="va">Mroz</span>, <span class="fu"><a href="https://rdrr.io/r/base/numeric.html" class="external-link">as.numeric</a></span><span class="op">(</span><span class="va">lfp</span> <span class="op">==</span> <span class="st">"yes"</span><span class="op">)</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/stats/fitted.values.html" class="external-link">fitted</a></span><span class="op">(</span><span class="va">m.mroz</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 0.26362</span></span></code></pre></div>
<p>Cross-validating this cost measure is straightforward:</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="st"><a href="https://gmonette.github.io/cv/">"cv"</a></span><span class="op">)</span></span>
<span><span class="co">#&gt; Loading required package: doParallel</span></span>
<span><span class="co">#&gt; Loading required package: foreach</span></span>
<span><span class="co">#&gt; Loading required package: iterators</span></span>
<span><span class="co">#&gt; Loading required package: parallel</span></span>
<span><span class="fu"><a href="../reference/cv.html">cv</a></span><span class="op">(</span><span class="va">m.mroz</span>, criterion<span class="op">=</span><span class="va">AUCcomp</span>, seed<span class="op">=</span><span class="fl">3639</span><span class="op">)</span></span>
<span><span class="co">#&gt; R RNG seed set to 3639</span></span>
<span><span class="co">#&gt; 10-Fold Cross Validation</span></span>
<span><span class="co">#&gt; criterion: AUCcomp</span></span>
<span><span class="co">#&gt; cross-validation criterion = 0.27471</span></span>
<span><span class="co">#&gt; full-sample criterion = 0.26362</span></span></code></pre></div>
<p>As expected, the cross-validated complement to the AUC is somewhat
less optimistic than the criterion computed from the model fit to the
whole data set.</p>
<p>As we explain in the vignette “Cross-validation of regression
models,” the <code><a href="../reference/cv.html">cv()</a></code> function differentiates between CV
criteria that are averages of casewise components and criteria that are
not. Computation of bias corrections and confidence intervals is limited
to the former. We show in the appendix to this vignette that the AUC,
and hence its complement, cannot be expressed as averages of casewise
components.</p>
<p><code><a href="../reference/cv.html">cv()</a></code> looks for a <code>"casewise loss"</code> attribute
of the value returned by a CV criterion function. If this attribute
exists, then the criterion is treated as the mean of casewise
components, and <code><a href="../reference/cv.html">cv()</a></code> uses the unexported function
<code>getLossFn()</code> to construct a function that returns the
casewise components of the criterion.</p>
<p>We illustrate with the <code><a href="../reference/cost-functions.html">mse()</a></code>:</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">mse</span></span>
<span><span class="co">#&gt; function (y, yhat) </span></span>
<span><span class="co">#&gt; {</span></span>
<span><span class="co">#&gt;     result &lt;- mean((y - yhat)^2)</span></span>
<span><span class="co">#&gt;     attr(result, "casewise loss") &lt;- "(y - yhat)^2"</span></span>
<span><span class="co">#&gt;     result</span></span>
<span><span class="co">#&gt; }</span></span>
<span><span class="co">#&gt; &lt;bytecode: 0x56485e51fe60&gt;</span></span>
<span><span class="co">#&gt; &lt;environment: namespace:cv&gt;</span></span>
<span></span>
<span><span class="fu">cv</span><span class="fu">:::</span><span class="fu">getLossFn</span><span class="op">(</span><span class="fu"><a href="../reference/cost-functions.html">mse</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="fl">100</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="fl">100</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; function (y, yhat) </span></span>
<span><span class="co">#&gt; {</span></span>
<span><span class="co">#&gt;     (y - yhat)^2</span></span>
<span><span class="co">#&gt; }</span></span>
<span><span class="co">#&gt; &lt;environment: 0x56485e42d6f8&gt;</span></span></code></pre></div>
<p>For this scheme to work, the “casewise loss” attribute must be a
character string (or vector of character strings), here
<code>"(y - yhat)^2"</code>, that evaluates to an expression that is a
function of <code>y</code> and <code>yhat</code>, and that computes the
vector of casewise components of the CV criterion.</p>
</div>
<div class="section level2">
<h2 id="adding-a-model-class-not-covered-by-the-default-cv-method">Adding a model class not covered by the default <code>cv()</code>
method<a class="anchor" aria-label="anchor" href="#adding-a-model-class-not-covered-by-the-default-cv-method"></a>
</h2>
<div class="section level3">
<h3 id="independently-sampled-cases">Independently sampled cases<a class="anchor" aria-label="anchor" href="#independently-sampled-cases"></a>
</h3>
<p>Suppose that we want to cross-validate a multinomial logistic
regression model fit by the <code><a href="https://rdrr.io/pkg/nnet/man/multinom.html" class="external-link">multinom()</a></code> function in the
<strong>nnet</strong> package <span class="citation">(Venables &amp;
Ripley, 2002)</span>. We borrow an example from <span class="citation">Fox (2016, sec. 14.2.1)</span>, with data from the
British Election Panel Study on vote choice in the 2001 British
election. Data for the example are in the <code>BEPS</code> data frame
in the <strong>carData</strong> package:</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/data.html" class="external-link">data</a></span><span class="op">(</span><span class="st">"BEPS"</span>, package<span class="op">=</span><span class="st">"carData"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">BEPS</span><span class="op">)</span></span>
<span><span class="co">#&gt;               vote age economic.cond.national economic.cond.household Blair</span></span>
<span><span class="co">#&gt; 1 Liberal Democrat  43                      3                       3     4</span></span>
<span><span class="co">#&gt; 2           Labour  36                      4                       4     4</span></span>
<span><span class="co">#&gt; 3           Labour  35                      4                       4     5</span></span>
<span><span class="co">#&gt; 4           Labour  24                      4                       2     2</span></span>
<span><span class="co">#&gt; 5           Labour  41                      2                       2     1</span></span>
<span><span class="co">#&gt; 6           Labour  47                      3                       4     4</span></span>
<span><span class="co">#&gt;   Hague Kennedy Europe political.knowledge gender</span></span>
<span><span class="co">#&gt; 1     1       4      2                   2 female</span></span>
<span><span class="co">#&gt; 2     4       4      5                   2   male</span></span>
<span><span class="co">#&gt; 3     2       3      3                   2   male</span></span>
<span><span class="co">#&gt; 4     1       3      4                   0 female</span></span>
<span><span class="co">#&gt; 5     1       4      6                   2   male</span></span>
<span><span class="co">#&gt; 6     4       2      4                   2   male</span></span></code></pre></div>
<p>The polytomous (multi-category) response variable is
<code>vote</code>, a factor with levels <code>"Conservative"</code>,
<code>"Labour"</code>, and <code>"Liberal Democrat"</code>. The
predictors of <code>vote</code> are:</p>
<ul>
<li>
<code>age</code>, in years;</li>
<li>
<code>econ.cond.national</code> and
<code>econ.cond.household</code>, the respondent’s ratings of the state
of the economy, on 1 to 5 scales.</li>
<li>
<code>Blair</code>, <code>Hague</code>, and <code>Kennedy</code>,
ratings of the leaders of the Labour, Conservative, and Liberal
Democratic parties, on 1 to 5 scales.</li>
<li>
<code>Europe</code>, an 11-point scale on attitude towards European
integration, with high scores representing “Euro-skepticism.”</li>
<li>
<code>political.knowledge</code>, knowledge of the parties’
positions on European integration, with scores from 0 to 3.</li>
<li>
<code>gender</code>, <code>"female"</code> or
<code>"male"</code>.</li>
</ul>
<p>The model fit to the data includes an interaction between
<code>Europe</code> and <code>political.knowledge</code>; the other
predictors enter the model additively:</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="st"><a href="http://www.stats.ox.ac.uk/pub/MASS4/" class="external-link">"nnet"</a></span><span class="op">)</span></span>
<span><span class="va">m.beps</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/nnet/man/multinom.html" class="external-link">multinom</a></span><span class="op">(</span><span class="va">vote</span> <span class="op">~</span> <span class="va">age</span> <span class="op">+</span> <span class="va">gender</span> <span class="op">+</span> <span class="va">economic.cond.national</span> <span class="op">+</span></span>
<span>                       <span class="va">economic.cond.household</span> <span class="op">+</span> <span class="va">Blair</span> <span class="op">+</span> <span class="va">Hague</span> <span class="op">+</span> <span class="va">Kennedy</span> <span class="op">+</span></span>
<span>                       <span class="va">Europe</span><span class="op">*</span><span class="va">political.knowledge</span>, data<span class="op">=</span><span class="va">BEPS</span><span class="op">)</span></span>
<span><span class="co">#&gt; # weights:  36 (22 variable)</span></span>
<span><span class="co">#&gt; initial  value 1675.383740 </span></span>
<span><span class="co">#&gt; iter  10 value 1240.047788</span></span>
<span><span class="co">#&gt; iter  20 value 1163.199642</span></span>
<span><span class="co">#&gt; iter  30 value 1116.519687</span></span>
<span><span class="co">#&gt; final  value 1116.519666 </span></span>
<span><span class="co">#&gt; converged</span></span>
<span></span>
<span><span class="fu">car</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/car/man/Anova.html" class="external-link">Anova</a></span><span class="op">(</span><span class="va">m.beps</span><span class="op">)</span></span>
<span><span class="co">#&gt; Analysis of Deviance Table (Type II tests)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Response: vote</span></span>
<span><span class="co">#&gt;                            LR Chisq Df Pr(&gt;Chisq)    </span></span>
<span><span class="co">#&gt; age                            13.9  2    0.00097 ***</span></span>
<span><span class="co">#&gt; gender                          0.5  2    0.79726    </span></span>
<span><span class="co">#&gt; economic.cond.national         30.6  2    2.3e-07 ***</span></span>
<span><span class="co">#&gt; economic.cond.household         5.7  2    0.05926 .  </span></span>
<span><span class="co">#&gt; Blair                         135.4  2    &lt; 2e-16 ***</span></span>
<span><span class="co">#&gt; Hague                         166.8  2    &lt; 2e-16 ***</span></span>
<span><span class="co">#&gt; Kennedy                        68.9  2    1.1e-15 ***</span></span>
<span><span class="co">#&gt; Europe                         78.0  2    &lt; 2e-16 ***</span></span>
<span><span class="co">#&gt; political.knowledge            55.6  2    8.6e-13 ***</span></span>
<span><span class="co">#&gt; Europe:political.knowledge     50.8  2    9.3e-12 ***</span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span></code></pre></div>
<p>Most of the predictors, including the <code>Europe</code> <span class="math inline">\(\times\)</span> <code>political.knowledge</code>
interaction, are associated with very small <span class="math inline">\(p\)</span>-values; the <code>Anova()</code>
function is from the <strong>car</strong> package <span class="citation">(Fox &amp; Weisberg, 2019)</span>.</p>
<p>Here’s an “effect plot”, using the the <strong>effects</strong>
package <span class="citation">(Fox &amp; Weisberg, 2019)</span> to
visualize the <code>Europe</code> <span class="math inline">\(\times\)</span> <code>political.knowledge</code>
interaction in a “stacked-area” graph:</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="fu">effects</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/effects/man/effect.html" class="external-link">Effect</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"Europe"</span>, <span class="st">"political.knowledge"</span><span class="op">)</span>, <span class="va">m.beps</span>,</span>
<span>            xlevels<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>Europe<span class="op">=</span><span class="fl">1</span><span class="op">:</span><span class="fl">11</span>, political.knowledge<span class="op">=</span><span class="fl">0</span><span class="op">:</span><span class="fl">3</span><span class="op">)</span>,</span>
<span>            fixed.predictors<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>given.values<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span>gendermale<span class="op">=</span><span class="fl">0.5</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>,</span>
<span>     lines<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>col<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"blue"</span>, <span class="st">"red"</span>, <span class="st">"orange"</span><span class="op">)</span><span class="op">)</span>,</span>
<span>     axes<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>x<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>rug<span class="op">=</span><span class="cn">FALSE</span><span class="op">)</span>, y<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>style<span class="op">=</span><span class="st">"stacked"</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p><img src="fig/BEPS-plot-1.png" width="864" style="display: block; margin: auto;"></p>
<p>To cross-validate this multinomial-logit model we need an appropriate
cost criterion. None of the criteria supplied by the <strong>cv</strong>
package—for example, neither <code><a href="../reference/cost-functions.html">mse()</a></code>, which is appropriate
for a numeric response, nor <code><a href="../reference/cost-functions.html">BayesRule()</a></code>, which is
appropriate for a binary response—will do. One possibility is to adapt
Bayes rule to a polytomous response:</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">BEPS</span><span class="op">$</span><span class="va">vote</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] Liberal Democrat Labour           Labour           Labour          </span></span>
<span><span class="co">#&gt; [5] Labour           Labour          </span></span>
<span><span class="co">#&gt; Levels: Conservative Labour Liberal Democrat</span></span>
<span><span class="va">yhat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">m.beps</span>, type<span class="op">=</span><span class="st">"class"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">yhat</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] Labour           Labour           Labour           Labour          </span></span>
<span><span class="co">#&gt; [5] Liberal Democrat Labour          </span></span>
<span><span class="co">#&gt; Levels: Conservative Labour Liberal Democrat</span></span>
<span></span>
<span><span class="va">BayesRuleMulti</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">y</span>, <span class="va">yhat</span><span class="op">)</span><span class="op">{</span></span>
<span>  <span class="va">result</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="va">y</span> <span class="op">!=</span> <span class="va">yhat</span><span class="op">)</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/attr.html" class="external-link">attr</a></span><span class="op">(</span><span class="va">result</span>, <span class="st">"casewise loss"</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="st">"y != yhat"</span></span>
<span>  <span class="va">result</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="fu">BayesRuleMulti</span><span class="op">(</span><span class="va">BEPS</span><span class="op">$</span><span class="va">vote</span>, <span class="va">yhat</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 0.31869</span></span>
<span><span class="co">#&gt; attr(,"casewise loss")</span></span>
<span><span class="co">#&gt; [1] "y != yhat"</span></span></code></pre></div>
<p>The <code><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict()</a></code> method for <code>"multinom"</code> models
called with argument <code>type="class"</code> reports the Bayes-rule
prediction for each case—that is, the response category with the highest
predicted probability. Our <code>BayesRuleMulti()</code> function
calculates the proportion of misclassified cases. Because this value is
the mean of casewise components, we attach a
<code>"casewise loss"</code> attribute to the result (as explained in
the preceding section).</p>
<p>The marginal proportions for the response categories are</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/xtabs.html" class="external-link">xtabs</a></span><span class="op">(</span><span class="op">~</span> <span class="va">vote</span>, data<span class="op">=</span><span class="va">BEPS</span><span class="op">)</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">BEPS</span><span class="op">)</span></span>
<span><span class="co">#&gt; vote</span></span>
<span><span class="co">#&gt;     Conservative           Labour Liberal Democrat </span></span>
<span><span class="co">#&gt;          0.30295          0.47213          0.22492</span></span></code></pre></div>
<p>and so the marginal Bayes-rule prediction, that everyone will vote
Labour, produces an error rate of <span class="math inline">\(1 -
0.47213 = 0.52787\)</span>. The multinomial-logit model appears to do
substantially better than that, but does its performance hold up to
cross-validation?</p>
<p>We check first whether the default <code><a href="../reference/cv.html">cv()</a></code> method works
“out-of-the-box” for the <code>"multinom"</code> model:</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/cv.html">cv</a></span><span class="op">(</span><span class="va">m.beps</span>, seed<span class="op">=</span><span class="fl">3465</span>, criterion<span class="op">=</span><span class="va">BayesRuleMulti</span><span class="op">)</span></span>
<span><span class="co">#&gt; Error in GetResponse.default(model): non-vector response</span></span></code></pre></div>
<p>The default method of <code><a href="../reference/GetResponse.html">GetResponse()</a></code> (a function supplied
by the <strong>cv</strong> package—see <code><a href="../reference/GetResponse.html">?GetResponse</a></code>) fails
for a <code>"multinom"</code> object. A straightforward solution is to
supply a <code>GetResponse.multinom()</code> method that returns the
factor response <span class="citation">(using the
<code>get_response()</code> function from the <strong>insight</strong>
package, Lüdecke, Waggoner, &amp; Makowski, 2019)</span>,</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">GetResponse.multinom</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">model</span>, <span class="va">...</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="fu">insight</span><span class="fu">::</span><span class="fu"><a href="https://easystats.github.io/insight/reference/get_response.html" class="external-link">get_response</a></span><span class="op">(</span><span class="va">model</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="fu"><a href="../reference/GetResponse.html">GetResponse</a></span><span class="op">(</span><span class="va">m.beps</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] Liberal Democrat Labour           Labour           Labour          </span></span>
<span><span class="co">#&gt; [5] Labour           Labour          </span></span>
<span><span class="co">#&gt; Levels: Conservative Labour Liberal Democrat</span></span></code></pre></div>
<p>and to try again:</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/cv.html">cv</a></span><span class="op">(</span><span class="va">m.beps</span>, seed<span class="op">=</span><span class="fl">3465</span>, criterion<span class="op">=</span><span class="va">BayesRuleMulti</span><span class="op">)</span></span>
<span><span class="co">#&gt; R RNG seed set to 3465</span></span>
<span><span class="co">#&gt; # weights:  36 (22 variable)</span></span>
<span><span class="co">#&gt; initial  value 1507.296060 </span></span>
<span><span class="co">#&gt; iter  10 value 1134.575036</span></span>
<span><span class="co">#&gt; iter  20 value 1037.413231</span></span>
<span><span class="co">#&gt; iter  30 value 1007.705242</span></span>
<span><span class="co">#&gt; iter  30 value 1007.705235</span></span>
<span><span class="co">#&gt; iter  30 value 1007.705235</span></span>
<span><span class="co">#&gt; final  value 1007.705235 </span></span>
<span><span class="co">#&gt; converged</span></span>
<span><span class="co">#&gt; Error in match.arg(type): 'arg' should be one of "class", "probs"</span></span></code></pre></div>
<p>A <code><a href="https://rdrr.io/r/base/traceback.html" class="external-link">traceback()</a></code> (not shown) reveals that the problem is
that the default method of <code><a href="../reference/cv.html">cv()</a></code> calls the
<code>"multinom"</code> method for <code><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict()</a></code> with the
argument <code>type="response"</code>, when the correct argument should
be <code>type="class"</code>. We therefore must write a
“<code>multinom</code>” method for <code><a href="../reference/cv.html">cv()</a></code>, but that proves to
be very simple:</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">cv.multinom</span> <span class="op">&lt;-</span> <span class="kw">function</span> <span class="op">(</span><span class="va">model</span>, <span class="va">data</span>, <span class="va">criterion</span><span class="op">=</span><span class="va">BayesRuleMulti</span>, <span class="va">k</span>, <span class="va">reps</span>,</span>
<span>                         <span class="va">seed</span>, <span class="va">...</span><span class="op">)</span><span class="op">{</span></span>
<span>  <span class="kw"><a href="https://rdrr.io/r/base/UseMethod.html" class="external-link">NextMethod</a></span><span class="op">(</span>type<span class="op">=</span><span class="st">"class"</span>, criterion<span class="op">=</span><span class="va">criterion</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code></pre></div>
<p>That is, we simply call the default <code><a href="../reference/cv.html">cv()</a></code> method with the
<code>type</code> argument properly set. In addition to supplying the
correct <code>type</code> argument, our method sets the default
<code>criterion</code> for the <code>cv.multinom()</code> method to
<code>BayesRuleMulti</code>.</p>
<p>Then:</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">m.beps</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/update.html" class="external-link">update</a></span><span class="op">(</span><span class="va">m.beps</span>, trace<span class="op">=</span><span class="cn">FALSE</span><span class="op">)</span></span>
<span><span class="fu"><a href="../reference/cv.html">cv</a></span><span class="op">(</span><span class="va">m.beps</span>, seed<span class="op">=</span><span class="fl">3465</span><span class="op">)</span></span>
<span><span class="co">#&gt; R RNG seed set to 3465</span></span>
<span><span class="co">#&gt; 10-Fold Cross Validation</span></span>
<span><span class="co">#&gt; cross-validation criterion = 0.32459</span></span>
<span><span class="co">#&gt; bias-adjusted cross-validation criterion = 0.32368</span></span>
<span><span class="co">#&gt; 95% CI for bias-adjusted CV criterion = (0.30017, 0.34718)</span></span>
<span><span class="co">#&gt; full-sample criterion = 0.31869</span></span></code></pre></div>
<p>Prior to invoking <code><a href="../reference/cv.html">cv()</a></code>, we called <code><a href="https://rdrr.io/r/stats/update.html" class="external-link">update()</a></code>
with <code>trace=FALSE</code> to suppress the iteration history reported
by default by <code><a href="https://rdrr.io/pkg/nnet/man/multinom.html" class="external-link">multinom()</a></code>—it would be tedious to see the
iteration history for each fold. The cross-validated polytomous
Bayes-rule criterion confirms that the fitted model does substantially
better than the marginal Bayes-rule prediction that everyone votes for
Labour.</p>
</div>
<div class="section level3">
<h3 id="mixed-effects-models">Mixed-effects models<a class="anchor" aria-label="anchor" href="#mixed-effects-models"></a>
</h3>
<p>Adding a <code><a href="../reference/cv.html">cv()</a></code> method for a mixed-model class is somewhat
more complicated. We provide the <code><a href="../reference/cvMixed.html">cvMixed()</a></code> function to
facilitate this process, and to see how that works, consider the
<code>"lme"</code> method from the <strong>cv</strong> package:</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">cv</span><span class="fu">:::</span><span class="va"><a href="../reference/cvMixed.html">cv.lme</a></span></span>
<span><span class="co">#&gt; function (model, data = insight::get_data(model), criterion = mse, </span></span>
<span><span class="co">#&gt;     k, reps = 1, seed, ncores = 1, clusterVariables, ...) </span></span>
<span><span class="co">#&gt; {</span></span>
<span><span class="co">#&gt;     cvMixed(model, package = "nlme", data = data, criterion = criterion, </span></span>
<span><span class="co">#&gt;         k = k, reps = reps, seed = seed, ncores = ncores, clusterVariables = clusterVariables, </span></span>
<span><span class="co">#&gt;         predict.clusters.args = list(object = model, newdata = data, </span></span>
<span><span class="co">#&gt;             level = 0), predict.cases.args = list(object = model, </span></span>
<span><span class="co">#&gt;             newdata = data, level = 1), ...)</span></span>
<span><span class="co">#&gt; }</span></span>
<span><span class="co">#&gt; &lt;bytecode: 0x5648671201d8&gt;</span></span>
<span><span class="co">#&gt; &lt;environment: namespace:cv&gt;</span></span></code></pre></div>
<p>Notice that <code><a href="../reference/cvMixed.html">cv.lme()</a></code> sets up a call to
<code><a href="../reference/cvMixed.html">cvMixed()</a></code>, which does the computational work.</p>
<p>Most of the arguments of <code><a href="../reference/cvMixed.html">cvMixed()</a></code> are familiar:</p>
<ul>
<li><p><code>model</code> is the mixed-model object, here of class
<code>"lme"</code>.</p></li>
<li><p><code>package</code> is the name of the package in which the
mixed-modeling function used to fit the model, here <code><a href="https://rdrr.io/pkg/nlme/man/lme.html" class="external-link">lme()</a></code>,
resides—i.e., <code>"nlme"</code>; <code><a href="../reference/cvMixed.html">cvMixed()</a></code> uses this
argument to retrieve the package namespace.</p></li>
<li><p><code>data</code> is the data set to which the model is fit, by
default extracted by the <code>get_data()</code> function in the
<strong>insight</strong> package.</p></li>
<li><p><code>criterion</code> is the CV criterion, defaulting to the
<code><a href="../reference/cost-functions.html">mse()</a></code> function.</p></li>
<li><p><code>k</code> is the number of CV folds, defaulting to
<code>"loo"</code> for CV by clusters and <code>10</code> for CV by
cases.</p></li>
<li><p><code>reps</code> is the number of times the CV process is
repeated, defaulting to <code>1</code>.</p></li>
<li><p><code>seed</code> is the seed for R’s random-number generator,
defaulting to a randomly selected (and saved) value.</p></li>
<li><p><code>ncores</code> is the number of cores to use for parallel
computation; if <code>1</code>, the default, then the computation isn’t
parallelized.</p></li>
<li><p><code>clusterVariables</code> is a character vector of the names
of variables defining clusters; if missing, then CV is based on cases
rather than clusters.</p></li>
</ul>
<p>The remaining two arguments are unfamiliar:</p>
<ul>
<li><p><code>predict.clusters.args</code> is a named list of arguments
to be passed to the <code><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict()</a></code> function to obtain
predictions for the full data set from a model fit to a subset of the
data for cluster-based CV. The first two arguments should be
<code>object</code> and <code>newdata</code>. It is typically necessary
to tell <code><a href="../reference/cvMixed.html">cvMixed()</a></code> how to base predictions only on fixed
effects; in the case of <code>"lme"</code> models, this is done by
setting <code>level = 0</code>.</p></li>
<li><p>Similarly, <code>predict.cases.args</code> is a named list of
arguments to be passed to <code><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict()</a></code> for case-based CV.
Setting <code>level = 1</code> includes random effects in the
predictions.</p></li>
</ul>
<p>Finally, any additional arguments, absorbed by <code>...</code>, are
passed to <code><a href="https://rdrr.io/r/stats/update.html" class="external-link">update()</a></code> when the model is refit with each fold
omitted. <code><a href="../reference/cvMixed.html">cvMixed()</a></code> returns an object of class
<code>"cv"</code>.</p>
<p>Now imagine that we want to support a new class of mixed-effects
models. To be concrete, we illustrate with the <code><a href="https://rdrr.io/pkg/MASS/man/glmmPQL.html" class="external-link">glmmPQL()</a></code>
function in the <strong>MASS</strong> package <span class="citation">(Venables &amp; Ripley, 2002)</span>, which fits
generalized-linear mixed-effects models by penalized quasi-likelihood.<a class="footnote-ref" tabindex="0" data-bs-toggle="popover" data-bs-content='&lt;p&gt;This example is somewhat artificial in that
&lt;code&gt;&lt;a href="https://rdrr.io/pkg/MASS/man/glmmPQL.html" class="external-link"&gt;glmmPQL()&lt;/a&gt;&lt;/code&gt; has largely been superseded by computationally
superior functions, such the &lt;code&gt;&lt;a href="https://rdrr.io/pkg/lme4/man/glmer.html" class="external-link"&gt;glmer()&lt;/a&gt;&lt;/code&gt; function in the
&lt;strong&gt;lme4&lt;/strong&gt; package. There is, however, one situation in which
&lt;code&gt;&lt;a href="https://rdrr.io/pkg/MASS/man/glmmPQL.html" class="external-link"&gt;glmmPQL()&lt;/a&gt;&lt;/code&gt; might prove useful: to specify serial dependency
in case-level errors within clusters for longitudinal data, which is not
currently supported by &lt;code&gt;&lt;a href="https://rdrr.io/pkg/lme4/man/glmer.html" class="external-link"&gt;glmer()&lt;/a&gt;&lt;/code&gt;.&lt;/p&gt;'><sup>1</sup></a> Not
coincidentally, the arguments of <code><a href="https://rdrr.io/pkg/MASS/man/glmmPQL.html" class="external-link">glmmPQL()</a></code> are similar to
those of <code><a href="https://rdrr.io/pkg/nlme/man/lme.html" class="external-link">lme()</a></code> (with an additional <code>family</code>
argument), because the former iteratively invokes the latter; so
<code>cv.glmmPQL()</code> should resemble <code><a href="../reference/cvMixed.html">cv.lme()</a></code>.</p>
<p>As it turns out, neither the default method for
<code><a href="../reference/GetResponse.html">GetResponse()</a></code> nor <code><a href="https://easystats.github.io/insight/reference/get_data.html" class="external-link">insight::get_data()</a></code> work for
<code>"glmmPQL"</code> objects. These objects include a
<code>"data"</code> element, however, and so we can simply extract this
element as the default for the <code>data</code> argument of our
<code>cv.glmmPQL()</code> method.</p>
<p>To get the response variable is more complicated: We refit the fixed
part of the model as a GLM with only the regression constant on the
right-hand side, and extract the response from that; because all we need
is the response variable, we limit the number of GLM iterations to 1 and
suppress warning messages about non-convergence:</p>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">GetResponse.glmmPQL</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">model</span>, <span class="va">...</span><span class="op">)</span><span class="op">{</span></span>
<span>  <span class="va">f</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/formula.html" class="external-link">formula</a></span><span class="op">(</span><span class="va">model</span><span class="op">)</span></span>
<span>  <span class="va">f</span><span class="op">[[</span><span class="fl">3</span><span class="op">]</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fl">1</span> <span class="co"># regression constant only on RHS</span></span>
<span>  <span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/warning.html" class="external-link">suppressWarnings</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/glm.html" class="external-link">glm</a></span><span class="op">(</span><span class="va">f</span>, data<span class="op">=</span><span class="va">model</span><span class="op">$</span><span class="va">data</span>, family<span class="op">=</span><span class="va">model</span><span class="op">$</span><span class="va">family</span>,</span>
<span>                                control<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>maxit<span class="op">=</span><span class="fl">1</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="fu">cv</span><span class="fu">::</span><span class="fu"><a href="../reference/GetResponse.html">GetResponse</a></span><span class="op">(</span><span class="va">model</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code></pre></div>
<p>Writing the <code><a href="../reference/cv.html">cv()</a></code> method is then straightforward:</p>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">cv.glmmPQL</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">model</span>, <span class="va">data</span> <span class="op">=</span> <span class="va">model</span><span class="op">$</span><span class="va">data</span>, <span class="va">criterion</span> <span class="op">=</span> <span class="va">mse</span>,</span>
<span>                     <span class="va">k</span>, <span class="va">reps</span> <span class="op">=</span> <span class="fl">1</span>, <span class="va">seed</span>, <span class="va">ncores</span> <span class="op">=</span> <span class="fl">1</span>, <span class="va">clusterVariables</span>, <span class="va">...</span><span class="op">)</span><span class="op">{</span></span>
<span>  <span class="fu"><a href="../reference/cvMixed.html">cvMixed</a></span><span class="op">(</span></span>
<span>    <span class="va">model</span>,</span>
<span>    package<span class="op">=</span><span class="st">"MASS"</span>,</span>
<span>    data<span class="op">=</span><span class="va">data</span>,</span>
<span>    criterion<span class="op">=</span><span class="va">criterion</span>,</span>
<span>    k<span class="op">=</span><span class="va">k</span>,</span>
<span>    reps<span class="op">=</span><span class="va">reps</span>,</span>
<span>    seed<span class="op">=</span><span class="va">seed</span>,</span>
<span>    ncores<span class="op">=</span><span class="va">ncores</span>,</span>
<span>    clusterVariables<span class="op">=</span><span class="va">clusterVariables</span>,</span>
<span>    predict.clusters.args<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>object<span class="op">=</span><span class="va">model</span>,</span>
<span>                               newdata<span class="op">=</span><span class="va">data</span>,</span>
<span>                               level<span class="op">=</span><span class="fl">0</span>,</span>
<span>                               type<span class="op">=</span><span class="st">"response"</span><span class="op">)</span>,</span>
<span>    predict.cases.args<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>object<span class="op">=</span><span class="va">model</span>,</span>
<span>                            newdata<span class="op">=</span><span class="va">data</span>,</span>
<span>                            level<span class="op">=</span><span class="fl">1</span>,</span>
<span>                            type<span class="op">=</span><span class="st">"response"</span><span class="op">)</span>,</span>
<span>    verbose<span class="op">=</span><span class="cn">FALSE</span>,</span>
<span>    <span class="va">...</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code></pre></div>
<p>We set the argument <code>verbose=FALSE</code> to suppress
<code><a href="https://rdrr.io/pkg/MASS/man/glmmPQL.html" class="external-link">glmmPQL()</a></code>’s iteration counter when <code><a href="../reference/cvMixed.html">cvMixed()</a></code>
calls <code><a href="https://rdrr.io/r/stats/update.html" class="external-link">update()</a></code>.</p>
<p>Let’s apply our newly minted method to a logistic regression with a
random intercept in an example that appears in
<code><a href="https://rdrr.io/pkg/MASS/man/glmmPQL.html" class="external-link">?glmmPQL</a></code>:</p>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="st"><a href="http://www.stats.ox.ac.uk/pub/MASS4/" class="external-link">"MASS"</a></span><span class="op">)</span></span>
<span><span class="va">m.pql</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/MASS/man/glmmPQL.html" class="external-link">glmmPQL</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="va">trt</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/AsIs.html" class="external-link">I</a></span><span class="op">(</span><span class="va">week</span> <span class="op">&gt;</span> <span class="fl">2</span><span class="op">)</span>, random <span class="op">=</span> <span class="op">~</span> <span class="fl">1</span> <span class="op">|</span> <span class="va">ID</span>,</span>
<span>             family <span class="op">=</span> <span class="va">binomial</span>, data <span class="op">=</span> <span class="va">bacteria</span><span class="op">)</span></span>
<span><span class="co">#&gt; iteration 1</span></span>
<span><span class="co">#&gt; iteration 2</span></span>
<span><span class="co">#&gt; iteration 3</span></span>
<span><span class="co">#&gt; iteration 4</span></span>
<span><span class="co">#&gt; iteration 5</span></span>
<span><span class="co">#&gt; iteration 6</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">m.pql</span><span class="op">)</span></span>
<span><span class="co">#&gt; Linear mixed-effects model fit by maximum likelihood</span></span>
<span><span class="co">#&gt;   Data: bacteria </span></span>
<span><span class="co">#&gt;   AIC BIC logLik</span></span>
<span><span class="co">#&gt;    NA  NA     NA</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Random effects:</span></span>
<span><span class="co">#&gt;  Formula: ~1 | ID</span></span>
<span><span class="co">#&gt;         (Intercept) Residual</span></span>
<span><span class="co">#&gt; StdDev:      1.4106  0.78005</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Variance function:</span></span>
<span><span class="co">#&gt;  Structure: fixed weights</span></span>
<span><span class="co">#&gt;  Formula: ~invwt </span></span>
<span><span class="co">#&gt; Fixed effects:  y ~ trt + I(week &gt; 2) </span></span>
<span><span class="co">#&gt;                   Value Std.Error  DF t-value p-value</span></span>
<span><span class="co">#&gt; (Intercept)      3.4120   0.51850 169  6.5805  0.0000</span></span>
<span><span class="co">#&gt; trtdrug         -1.2474   0.64406  47 -1.9367  0.0588</span></span>
<span><span class="co">#&gt; trtdrug+        -0.7543   0.64540  47 -1.1688  0.2484</span></span>
<span><span class="co">#&gt; I(week &gt; 2)TRUE -1.6073   0.35834 169 -4.4853  0.0000</span></span>
<span><span class="co">#&gt;  Correlation: </span></span>
<span><span class="co">#&gt;                 (Intr) trtdrg trtdr+</span></span>
<span><span class="co">#&gt; trtdrug         -0.598              </span></span>
<span><span class="co">#&gt; trtdrug+        -0.571  0.460       </span></span>
<span><span class="co">#&gt; I(week &gt; 2)TRUE -0.537  0.047 -0.001</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Standardized Within-Group Residuals:</span></span>
<span><span class="co">#&gt;      Min       Q1      Med       Q3      Max </span></span>
<span><span class="co">#&gt; -5.19854  0.15723  0.35131  0.49495  1.74488 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Number of Observations: 220</span></span>
<span><span class="co">#&gt; Number of Groups: 50</span></span></code></pre></div>
<p>We compare this result to that obtained from <code><a href="https://rdrr.io/pkg/lme4/man/glmer.html" class="external-link">glmer()</a></code> in
the <strong>lme4</strong> package:</p>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="st"><a href="https://github.com/lme4/lme4/" class="external-link">"lme4"</a></span><span class="op">)</span></span>
<span><span class="co">#&gt; Loading required package: Matrix</span></span>
<span><span class="va">m.glmer</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/lme4/man/glmer.html" class="external-link">glmer</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="va">trt</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/AsIs.html" class="external-link">I</a></span><span class="op">(</span><span class="va">week</span> <span class="op">&gt;</span> <span class="fl">2</span><span class="op">)</span> <span class="op">+</span> <span class="op">(</span><span class="fl">1</span> <span class="op">|</span> <span class="va">ID</span><span class="op">)</span>,</span>
<span>               family <span class="op">=</span> <span class="va">binomial</span>, data <span class="op">=</span> <span class="va">bacteria</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">m.glmer</span><span class="op">)</span></span>
<span><span class="co">#&gt; Generalized linear mixed model fit by maximum likelihood (Laplace</span></span>
<span><span class="co">#&gt;   Approximation) [glmerMod]</span></span>
<span><span class="co">#&gt;  Family: binomial  ( logit )</span></span>
<span><span class="co">#&gt; Formula: y ~ trt + I(week &gt; 2) + (1 | ID)</span></span>
<span><span class="co">#&gt;    Data: bacteria</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;      AIC      BIC   logLik deviance df.resid </span></span>
<span><span class="co">#&gt;    202.3    219.2    -96.1    192.3      215 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Scaled residuals: </span></span>
<span><span class="co">#&gt;    Min     1Q Median     3Q    Max </span></span>
<span><span class="co">#&gt; -4.561  0.136  0.302  0.422  1.128 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Random effects:</span></span>
<span><span class="co">#&gt;  Groups Name        Variance Std.Dev.</span></span>
<span><span class="co">#&gt;  ID     (Intercept) 1.54     1.24    </span></span>
<span><span class="co">#&gt; Number of obs: 220, groups:  ID, 50</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Fixed effects:</span></span>
<span><span class="co">#&gt;                 Estimate Std. Error z value Pr(&gt;|z|)    </span></span>
<span><span class="co">#&gt; (Intercept)        3.548      0.696    5.10  3.4e-07 ***</span></span>
<span><span class="co">#&gt; trtdrug           -1.367      0.677   -2.02  0.04352 *  </span></span>
<span><span class="co">#&gt; trtdrug+          -0.783      0.683   -1.15  0.25193    </span></span>
<span><span class="co">#&gt; I(week &gt; 2)TRUE   -1.598      0.476   -3.36  0.00078 ***</span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Correlation of Fixed Effects:</span></span>
<span><span class="co">#&gt;             (Intr) trtdrg trtdr+</span></span>
<span><span class="co">#&gt; trtdrug     -0.593              </span></span>
<span><span class="co">#&gt; trtdrug+    -0.537  0.487       </span></span>
<span><span class="co">#&gt; I(wk&gt;2)TRUE -0.656  0.126  0.064</span></span>
<span></span>
<span>  <span class="co"># comparison of fixed effects:</span></span>
<span><span class="fu">car</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/car/man/compareCoefs.html" class="external-link">compareCoefs</a></span><span class="op">(</span><span class="va">m.pql</span>, <span class="va">m.glmer</span><span class="op">)</span> </span>
<span><span class="co">#&gt; Warning in car::compareCoefs(m.pql, m.glmer): models to be compared are of</span></span>
<span><span class="co">#&gt; different classes</span></span>
<span><span class="co">#&gt; Calls:</span></span>
<span><span class="co">#&gt; 1: glmmPQL(fixed = y ~ trt + I(week &gt; 2), random = ~1 | ID, family = </span></span>
<span><span class="co">#&gt;   binomial, data = bacteria)</span></span>
<span><span class="co">#&gt; 2: glmer(formula = y ~ trt + I(week &gt; 2) + (1 | ID), data = bacteria, </span></span>
<span><span class="co">#&gt;   family = binomial)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;                 Model 1 Model 2</span></span>
<span><span class="co">#&gt; (Intercept)       3.412   3.548</span></span>
<span><span class="co">#&gt; SE                0.514   0.696</span></span>
<span><span class="co">#&gt;                                </span></span>
<span><span class="co">#&gt; trtdrug          -1.247  -1.367</span></span>
<span><span class="co">#&gt; SE                0.638   0.677</span></span>
<span><span class="co">#&gt;                                </span></span>
<span><span class="co">#&gt; trtdrug+         -0.754  -0.783</span></span>
<span><span class="co">#&gt; SE                0.640   0.683</span></span>
<span><span class="co">#&gt;                                </span></span>
<span><span class="co">#&gt; I(week &gt; 2)TRUE  -1.607  -1.598</span></span>
<span><span class="co">#&gt; SE                0.355   0.476</span></span>
<span><span class="co">#&gt; </span></span></code></pre></div>
<p>The two sets of estimates are similar, but not identical</p>
<p>Finally, we try out our <code>cv.glmmPQL()</code> method,
cross-validating both by clusters and by cases,</p>
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/cv.html">cv</a></span><span class="op">(</span><span class="va">m.pql</span>, clusterVariables<span class="op">=</span><span class="st">"ID"</span>, criterion<span class="op">=</span><span class="va">BayesRule</span><span class="op">)</span></span>
<span><span class="co">#&gt; n-Fold Cross Validation based on 50 {ID} clusters</span></span>
<span><span class="co">#&gt; cross-validation criterion = 0.19545</span></span>
<span><span class="co">#&gt; bias-adjusted cross-validation criterion = 0.19545</span></span>
<span><span class="co">#&gt; full-sample criterion = 0.19545</span></span>
<span></span>
<span><span class="fu"><a href="../reference/cv.html">cv</a></span><span class="op">(</span><span class="va">m.pql</span>, data<span class="op">=</span><span class="va">bacteria</span>, criterion<span class="op">=</span><span class="va">BayesRule</span>, seed<span class="op">=</span><span class="fl">1490</span><span class="op">)</span></span>
<span><span class="co">#&gt; R RNG seed set to 1490</span></span>
<span><span class="co">#&gt; 10-Fold Cross Validation</span></span>
<span><span class="co">#&gt; cross-validation criterion = 0.20909</span></span>
<span><span class="co">#&gt; bias-adjusted cross-validation criterion = 0.20727</span></span>
<span><span class="co">#&gt; full-sample criterion = 0.14545</span></span></code></pre></div>
<p>and again compare to <code><a href="https://rdrr.io/pkg/lme4/man/glmer.html" class="external-link">glmer()</a></code>:</p>
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/cv.html">cv</a></span><span class="op">(</span><span class="va">m.glmer</span>, clusterVariables<span class="op">=</span><span class="st">"ID"</span>, criterion<span class="op">=</span><span class="va">BayesRule</span><span class="op">)</span></span>
<span><span class="co">#&gt; n-Fold Cross Validation based on 50 {ID} clusters</span></span>
<span><span class="co">#&gt; cross-validation criterion = 0.19545</span></span>
<span><span class="co">#&gt; bias-adjusted cross-validation criterion = 0.19545</span></span>
<span><span class="co">#&gt; full-sample criterion = 0.19545</span></span>
<span></span>
<span><span class="fu"><a href="../reference/cv.html">cv</a></span><span class="op">(</span><span class="va">m.glmer</span>, data<span class="op">=</span><span class="va">bacteria</span>, criterion<span class="op">=</span><span class="va">BayesRule</span>, seed<span class="op">=</span><span class="fl">1490</span><span class="op">)</span></span>
<span><span class="co">#&gt; R RNG seed set to 1490</span></span>
<span><span class="co">#&gt; 10-Fold Cross Validation</span></span>
<span><span class="co">#&gt; cross-validation criterion = 0.19545</span></span>
<span><span class="co">#&gt; bias-adjusted cross-validation criterion = 0.19364</span></span>
<span><span class="co">#&gt; full-sample criterion = 0.15</span></span></code></pre></div>
</div>
</div>
<div class="section level2">
<h2 id="adding-a-model-selection-procedure">Adding a model-selection procedure<a class="anchor" aria-label="anchor" href="#adding-a-model-selection-procedure"></a>
</h2>
<p>The <code><a href="../reference/cvSelect.html">selectStepAIC()</a></code> function supplied by the
<strong>cv</strong> package, which is based on the
<code><a href="https://rdrr.io/pkg/MASS/man/stepAIC.html" class="external-link">stepAIC()</a></code> function from the <strong>nnet</strong> package
<span class="citation">(Venables &amp; Ripley, 2002)</span> for stepwise
model selection, is suitable for the <code>procedure</code> argument of
<code><a href="../reference/cvSelect.html">cvSelect()</a></code>. The use of <code><a href="../reference/cvSelect.html">selectStepAIC()</a></code> is
illustrated in the principal vignette for the package.</p>
<p>We’ll employ <code><a href="../reference/cvSelect.html">selectStepAIC()</a></code> as a “template” for writing
a CV model-selection procedure. To see the code for this function, type
<code><a href="../reference/cvSelect.html">cv::selectStepAIC</a></code> at the R command prompt, or examine the
sources for the <strong>cv</strong> package at <a href="https://github.com/gmonette/cv" class="external-link uri">https://github.com/gmonette/cv</a> (the code for
<code><a href="../reference/cvSelect.html">selectStepAIC()</a></code> is in <a href="https://github.com/gmonette/cv/blob/main/R/cvSelect.R" class="external-link uri">https://github.com/gmonette/cv/blob/main/R/cvSelect.R</a>).</p>
<p>Another approach to model selection is all-subsets regression. The
<code><a href="https://rdrr.io/pkg/leaps/man/regsubsets.html" class="external-link">regsubsets()</a></code> function in the <strong>leaps</strong> package
<span class="citation">(Lumley &amp; Miller, 2020)</span> implements an
efficient algorithm for selecting the best-fitting linear least-squares
regressions for subsets of predictors of all sizes, from 1 through the
maximum number of candidate predictors.<a class="footnote-ref" tabindex="0" data-bs-toggle="popover" data-bs-content='&lt;p&gt;The &lt;code&gt;&lt;a href="https://rdrr.io/pkg/leaps/man/regsubsets.html" class="external-link"&gt;regsubsets()&lt;/a&gt;&lt;/code&gt; function computes several
measures of model predictive performance, including the &lt;span class="math inline"&gt;\(R^2\)&lt;/span&gt; and &lt;span class="math inline"&gt;\(R^2\)&lt;/span&gt; adjusted for degrees of freedom, the
residual sums of squares, Mallows’s &lt;span class="math inline"&gt;\(C_p\)&lt;/span&gt;, and the BIC. Several of these are
suitable for comparing models with differing numbers of coefficients—we
use the BIC below—but all necessarily agree when comparing models with
the &lt;em&gt;same&lt;/em&gt; number of coefficients.&lt;/p&gt;'><sup>2</sup></a> To illustrate the use
of <code><a href="https://rdrr.io/pkg/leaps/man/regsubsets.html" class="external-link">regsubsets()</a></code>, we employ the <code>swiss</code> data
frame supplied by the <strong>leaps</strong> package:</p>
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="st">"leaps"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">swiss</span><span class="op">)</span></span>
<span><span class="co">#&gt;              Fertility Agriculture Examination Education Catholic</span></span>
<span><span class="co">#&gt; Courtelary        80.2        17.0          15        12     9.96</span></span>
<span><span class="co">#&gt; Delemont          83.1        45.1           6         9    84.84</span></span>
<span><span class="co">#&gt; Franches-Mnt      92.5        39.7           5         5    93.40</span></span>
<span><span class="co">#&gt; Moutier           85.8        36.5          12         7    33.77</span></span>
<span><span class="co">#&gt; Neuveville        76.9        43.5          17        15     5.16</span></span>
<span><span class="co">#&gt; Porrentruy        76.1        35.3           9         7    90.57</span></span>
<span><span class="co">#&gt;              Infant.Mortality</span></span>
<span><span class="co">#&gt; Courtelary               22.2</span></span>
<span><span class="co">#&gt; Delemont                 22.2</span></span>
<span><span class="co">#&gt; Franches-Mnt             20.2</span></span>
<span><span class="co">#&gt; Moutier                  20.3</span></span>
<span><span class="co">#&gt; Neuveville               20.6</span></span>
<span><span class="co">#&gt; Porrentruy               26.6</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">swiss</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 47</span></span></code></pre></div>
<p>The data set includes the following variables, for each of 47
French-speaking Swiss provinces circa 1888:</p>
<ul>
<li>
<code>Fertility</code>: A standardized fertility measure.</li>
<li>
<code>Agriculture</code>: The percentage of the male population
engaged in agriculture.</li>
<li>
<code>Examination</code>: The percentage of draftees into the Swiss
army receiving the highest grade on an examination.</li>
<li>
<code>Education</code>: The percentage of draftees with more than a
primary-school education.</li>
<li>
<code>Catholic</code>: The percentage of the population who were
Catholic.</li>
<li>
<code>Infant.Mortality</code>: The infant-mortality rate, expressed
as the percentage of live births surviving less than a year.</li>
</ul>
<p>Following <span class="citation">Lumley &amp; Miller (2020)</span>,
we treat <code>Fertility</code> as the response and the other variables
as predictors in a linear least-squares regression:</p>
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">m.swiss</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html" class="external-link">lm</a></span><span class="op">(</span><span class="va">Fertility</span> <span class="op">~</span> <span class="va">.</span>, data<span class="op">=</span><span class="va">swiss</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">m.swiss</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:</span></span>
<span><span class="co">#&gt; lm(formula = Fertility ~ ., data = swiss)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Residuals:</span></span>
<span><span class="co">#&gt;     Min      1Q  Median      3Q     Max </span></span>
<span><span class="co">#&gt; -15.274  -5.262   0.503   4.120  15.321 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Coefficients:</span></span>
<span><span class="co">#&gt;                  Estimate Std. Error t value Pr(&gt;|t|)    </span></span>
<span><span class="co">#&gt; (Intercept)       66.9152    10.7060    6.25  1.9e-07 ***</span></span>
<span><span class="co">#&gt; Agriculture       -0.1721     0.0703   -2.45   0.0187 *  </span></span>
<span><span class="co">#&gt; Examination       -0.2580     0.2539   -1.02   0.3155    </span></span>
<span><span class="co">#&gt; Education         -0.8709     0.1830   -4.76  2.4e-05 ***</span></span>
<span><span class="co">#&gt; Catholic           0.1041     0.0353    2.95   0.0052 ** </span></span>
<span><span class="co">#&gt; Infant.Mortality   1.0770     0.3817    2.82   0.0073 ** </span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Residual standard error: 7.17 on 41 degrees of freedom</span></span>
<span><span class="co">#&gt; Multiple R-squared:  0.707,  Adjusted R-squared:  0.671 </span></span>
<span><span class="co">#&gt; F-statistic: 19.8 on 5 and 41 DF,  p-value: 5.59e-10</span></span>
<span></span>
<span><span class="fu"><a href="../reference/cv.html">cv</a></span><span class="op">(</span><span class="va">m.swiss</span>, seed<span class="op">=</span><span class="fl">8433</span><span class="op">)</span></span>
<span><span class="co">#&gt; R RNG seed set to 8433</span></span>
<span><span class="co">#&gt; 10-Fold Cross Validation</span></span>
<span><span class="co">#&gt; method: Woodbury</span></span>
<span><span class="co">#&gt; criterion: mse</span></span>
<span><span class="co">#&gt; cross-validation criterion = 59.683</span></span>
<span><span class="co">#&gt; bias-adjusted cross-validation criterion = 58.846</span></span>
<span><span class="co">#&gt; full-sample criterion = 44.788</span></span></code></pre></div>
<p>Thus, the RMSE for the model fit to the complete data is considerably
smaller than the CV estimate of the RMSE. Can we do better by selecting
a subset of the predictors, taking account of the additional uncertainty
induced by model selection?</p>
<p>First, let’s apply best-subset selection to the complete data
set:</p>
<div class="sourceCode" id="cb24"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">swiss.sub</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/leaps/man/regsubsets.html" class="external-link">regsubsets</a></span><span class="op">(</span><span class="va">Fertility</span> <span class="op">~</span> <span class="va">.</span>, data<span class="op">=</span><span class="va">swiss</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">swiss.sub</span><span class="op">)</span></span>
<span><span class="co">#&gt; Subset selection object</span></span>
<span><span class="co">#&gt; Call: regsubsets.formula(Fertility ~ ., data = swiss)</span></span>
<span><span class="co">#&gt; 5 Variables  (and intercept)</span></span>
<span><span class="co">#&gt;                  Forced in Forced out</span></span>
<span><span class="co">#&gt; Agriculture          FALSE      FALSE</span></span>
<span><span class="co">#&gt; Examination          FALSE      FALSE</span></span>
<span><span class="co">#&gt; Education            FALSE      FALSE</span></span>
<span><span class="co">#&gt; Catholic             FALSE      FALSE</span></span>
<span><span class="co">#&gt; Infant.Mortality     FALSE      FALSE</span></span>
<span><span class="co">#&gt; 1 subsets of each size up to 5</span></span>
<span><span class="co">#&gt; Selection Algorithm: exhaustive</span></span>
<span><span class="co">#&gt;          Agriculture Examination Education Catholic Infant.Mortality</span></span>
<span><span class="co">#&gt; 1  ( 1 ) " "         " "         "*"       " "      " "             </span></span>
<span><span class="co">#&gt; 2  ( 1 ) " "         " "         "*"       "*"      " "             </span></span>
<span><span class="co">#&gt; 3  ( 1 ) " "         " "         "*"       "*"      "*"             </span></span>
<span><span class="co">#&gt; 4  ( 1 ) "*"         " "         "*"       "*"      "*"             </span></span>
<span><span class="co">#&gt; 5  ( 1 ) "*"         "*"         "*"       "*"      "*"</span></span>
<span></span>
<span><span class="op">(</span><span class="va">bics</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">swiss.sub</span><span class="op">)</span><span class="op">$</span><span class="va">bic</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] -19.603 -28.611 -35.656 -37.234 -34.553</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/which.min.html" class="external-link">which.min</a></span><span class="op">(</span><span class="va">bics</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 4</span></span>
<span></span>
<span><span class="fu">car</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/car/man/subsets.html" class="external-link">subsets</a></span><span class="op">(</span><span class="va">swiss.sub</span>, legend<span class="op">=</span><span class="st">"topright"</span><span class="op">)</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<img src="fig/subset-selection-1.png" alt="Selecting the best model of each size." width="672"><p class="caption">
Selecting the best model of each size.
</p>
</div>
<p>The graph, produced by the <code>subsets()</code> function in the
<strong>car</strong> package, shows that the model with the smallest BIC
is the best model with 4 predictors, including <code>Agriculture</code>,
<code>Education</code>, <code>Catholic</code>, and
<code>Infant.Mortality</code>, but not <code>Examination</code>:</p>
<div class="sourceCode" id="cb25"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">m.best</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/update.html" class="external-link">update</a></span><span class="op">(</span><span class="va">m.swiss</span>, <span class="va">.</span> <span class="op">~</span> <span class="va">.</span> <span class="op">-</span> <span class="va">Examination</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">m.best</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:</span></span>
<span><span class="co">#&gt; lm(formula = Fertility ~ Agriculture + Education + Catholic + </span></span>
<span><span class="co">#&gt;     Infant.Mortality, data = swiss)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Residuals:</span></span>
<span><span class="co">#&gt;     Min      1Q  Median      3Q     Max </span></span>
<span><span class="co">#&gt; -14.676  -6.052   0.751   3.166  16.142 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Coefficients:</span></span>
<span><span class="co">#&gt;                  Estimate Std. Error t value Pr(&gt;|t|)    </span></span>
<span><span class="co">#&gt; (Intercept)       62.1013     9.6049    6.47  8.5e-08 ***</span></span>
<span><span class="co">#&gt; Agriculture       -0.1546     0.0682   -2.27   0.0286 *  </span></span>
<span><span class="co">#&gt; Education         -0.9803     0.1481   -6.62  5.1e-08 ***</span></span>
<span><span class="co">#&gt; Catholic           0.1247     0.0289    4.31  9.5e-05 ***</span></span>
<span><span class="co">#&gt; Infant.Mortality   1.0784     0.3819    2.82   0.0072 ** </span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Residual standard error: 7.17 on 42 degrees of freedom</span></span>
<span><span class="co">#&gt; Multiple R-squared:  0.699,  Adjusted R-squared:  0.671 </span></span>
<span><span class="co">#&gt; F-statistic: 24.4 on 4 and 42 DF,  p-value: 1.72e-10</span></span>
<span></span>
<span><span class="fu"><a href="../reference/cv.html">cv</a></span><span class="op">(</span><span class="va">m.best</span>, seed<span class="op">=</span><span class="fl">8433</span><span class="op">)</span> <span class="co"># use same folds as before</span></span>
<span><span class="co">#&gt; R RNG seed set to 8433</span></span>
<span><span class="co">#&gt; 10-Fold Cross Validation</span></span>
<span><span class="co">#&gt; method: Woodbury</span></span>
<span><span class="co">#&gt; criterion: mse</span></span>
<span><span class="co">#&gt; cross-validation criterion = 58.467</span></span>
<span><span class="co">#&gt; bias-adjusted cross-validation criterion = 57.778</span></span>
<span><span class="co">#&gt; full-sample criterion = 45.916</span></span></code></pre></div>
<p>The RMSE for the selected model is (of course) slightly higher than
for the full model fit previously, but the cross-validated RMSE is a bit
lower; as we explain in the main vignette, however, it isn’t kosher to
select and cross-validate a model on the same data.</p>
<p>Here’s a function named <code>selectSubsets()</code>, meant to be
used with <code><a href="../reference/cvSelect.html">cvSelect()</a></code>, suitable for cross-validating the
model-selection process:</p>
<div class="sourceCode" id="cb26"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">selectSubsets</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">data</span><span class="op">=</span><span class="fu">insight</span><span class="fu">::</span><span class="fu"><a href="https://easystats.github.io/insight/reference/get_data.html" class="external-link">get_data</a></span><span class="op">(</span><span class="va">model</span><span class="op">)</span>, </span>
<span>                          <span class="va">model</span>,</span>
<span>                          <span class="va">indices</span>,</span>
<span>                          <span class="va">criterion</span><span class="op">=</span><span class="va">mse</span>,</span>
<span>                          <span class="va">save.coef</span><span class="op">=</span><span class="cn">TRUE</span>, <span class="va">...</span><span class="op">)</span><span class="op">{</span></span>
<span>  </span>
<span>  <span class="kw">if</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/class.html" class="external-link">inherits</a></span><span class="op">(</span><span class="va">model</span>, <span class="st">"lm"</span>, which<span class="op">=</span><span class="cn">TRUE</span><span class="op">)</span> <span class="op">!=</span> <span class="fl">1</span><span class="op">)</span></span>
<span>    <span class="kw"><a href="https://rdrr.io/r/base/stop.html" class="external-link">stop</a></span><span class="op">(</span><span class="st">"selectSubsets is appropriate only for 'lm' models"</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="va">y</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/GetResponse.html">GetResponse</a></span><span class="op">(</span><span class="va">model</span><span class="op">)</span></span>
<span>  <span class="va">formula</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/formula.html" class="external-link">formula</a></span><span class="op">(</span><span class="va">model</span><span class="op">)</span></span>
<span>  <span class="va">X</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/model.matrix.html" class="external-link">model.matrix</a></span><span class="op">(</span><span class="va">model</span><span class="op">)</span></span>
<span></span>
<span>  <span class="kw">if</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/missing.html" class="external-link">missing</a></span><span class="op">(</span><span class="va">indices</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="co"># select the best model from the full data by BIC</span></span>
<span>    <span class="va">sel</span> <span class="op">&lt;-</span> <span class="fu">leaps</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/leaps/man/regsubsets.html" class="external-link">regsubsets</a></span><span class="op">(</span><span class="va">formula</span>, data<span class="op">=</span><span class="va">data</span>, <span class="va">...</span><span class="op">)</span></span>
<span>    <span class="va">bics</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">sel</span><span class="op">)</span><span class="op">$</span><span class="va">bic</span></span>
<span>    <span class="va">best</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/coef.html" class="external-link">coef</a></span><span class="op">(</span><span class="va">sel</span>, <span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">bics</span><span class="op">)</span><span class="op">)</span><span class="op">[[</span><span class="fu"><a href="https://rdrr.io/r/base/which.min.html" class="external-link">which.min</a></span><span class="op">(</span><span class="va">bics</span><span class="op">)</span><span class="op">]</span><span class="op">]</span></span>
<span>    <span class="va">x.names</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/names.html" class="external-link">names</a></span><span class="op">(</span><span class="va">best</span><span class="op">)</span></span>
<span>    <span class="co"># fit the best model; intercept is already in X, hence - 1:</span></span>
<span>    <span class="va">m.best</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html" class="external-link">lm</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="va">X</span><span class="op">[</span>, <span class="va">x.names</span><span class="op">]</span> <span class="op">-</span> <span class="fl">1</span><span class="op">)</span> </span>
<span>    <span class="va">fit.all</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">m.best</span>, newdata<span class="op">=</span><span class="va">data</span><span class="op">)</span></span>
<span>    <span class="kw"><a href="https://rdrr.io/r/base/function.html" class="external-link">return</a></span><span class="op">(</span><span class="fu">criterion</span><span class="op">(</span><span class="va">y</span>, <span class="va">fit.all</span><span class="op">)</span><span class="op">)</span> <span class="co"># return the CV criterion</span></span>
<span>  <span class="op">}</span></span>
<span></span>
<span>  <span class="co"># select the best model omitting the i-th fold (given by indices)</span></span>
<span>  <span class="va">sel.i</span> <span class="op">&lt;-</span> <span class="fu">leaps</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/leaps/man/regsubsets.html" class="external-link">regsubsets</a></span><span class="op">(</span><span class="va">formula</span>, <span class="va">data</span><span class="op">[</span><span class="op">-</span><span class="va">indices</span>, <span class="op">]</span>, <span class="va">...</span><span class="op">)</span></span>
<span>  <span class="va">bics.i</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">sel.i</span><span class="op">)</span><span class="op">$</span><span class="va">bic</span></span>
<span>  <span class="va">best.i</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/coef.html" class="external-link">coef</a></span><span class="op">(</span><span class="va">sel.i</span>, <span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">bics.i</span><span class="op">)</span><span class="op">)</span><span class="op">[[</span><span class="fu"><a href="https://rdrr.io/r/base/which.min.html" class="external-link">which.min</a></span><span class="op">(</span><span class="va">bics.i</span><span class="op">)</span><span class="op">]</span><span class="op">]</span></span>
<span>  <span class="va">x.names.i</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/names.html" class="external-link">names</a></span><span class="op">(</span><span class="va">best.i</span><span class="op">)</span></span>
<span>  <span class="va">m.best.i</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html" class="external-link">lm</a></span><span class="op">(</span><span class="va">y</span><span class="op">[</span><span class="op">-</span><span class="va">indices</span><span class="op">]</span> <span class="op">~</span> <span class="va">X</span><span class="op">[</span><span class="op">-</span><span class="va">indices</span>, <span class="va">x.names.i</span><span class="op">]</span> <span class="op">-</span> <span class="fl">1</span><span class="op">)</span></span>
<span>              <span class="co"># predict() doesn't work here:</span></span>
<span>  <span class="va">fit.all.i</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/vector.html" class="external-link">as.vector</a></span><span class="op">(</span><span class="va">X</span><span class="op">[</span>, <span class="va">x.names.i</span><span class="op">]</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="fu"><a href="https://rdrr.io/r/stats/coef.html" class="external-link">coef</a></span><span class="op">(</span><span class="va">m.best.i</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="va">fit.i</span> <span class="op">&lt;-</span> <span class="va">fit.all.i</span><span class="op">[</span><span class="va">indices</span><span class="op">]</span></span>
<span>  <span class="co"># return the fitted values for i-th fold, CV criterion for all cases, </span></span>
<span>  <span class="co">#   and the regression coefficients</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>fit.i<span class="op">=</span><span class="va">fit.i</span>, <span class="co"># fitted values for i-th fold</span></span>
<span>       crit.all.i<span class="op">=</span><span class="fu">criterion</span><span class="op">(</span><span class="va">y</span>, <span class="va">fit.all.i</span><span class="op">)</span>, <span class="co"># CV crit for all cases</span></span>
<span>       coefficients <span class="op">=</span> <span class="kw">if</span> <span class="op">(</span><span class="va">save.coef</span><span class="op">)</span><span class="op">{</span> <span class="co"># regression coefficients</span></span>
<span>         <span class="va">coefs</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/coef.html" class="external-link">coef</a></span><span class="op">(</span><span class="va">m.best.i</span><span class="op">)</span></span>
<span>         </span>
<span>         <span class="co"># fix coefficient names</span></span>
<span>         <span class="fu"><a href="https://rdrr.io/r/base/names.html" class="external-link">names</a></span><span class="op">(</span><span class="va">coefs</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/grep.html" class="external-link">sub</a></span><span class="op">(</span><span class="st">"X\\[-indices, x.names.i\\]"</span>, <span class="st">""</span>,</span>
<span>                             <span class="fu"><a href="https://rdrr.io/r/base/names.html" class="external-link">names</a></span><span class="op">(</span><span class="va">coefs</span><span class="op">)</span><span class="op">)</span></span>
<span>         </span>
<span>         <span class="va">coefs</span></span>
<span>       <span class="op">}</span>  <span class="kw">else</span> <span class="op">{</span></span>
<span>         <span class="cn">NULL</span></span>
<span>       <span class="op">}</span></span>
<span>  <span class="op">)</span></span>
<span><span class="op">}</span></span></code></pre></div>
<p>A slightly tricky point is that because of scoping issues,
<code><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict()</a></code> doesn’t work with the model fit omitting the
<span class="math inline">\(i\)</span>th fold, and so the fitted values
for all cases are computed directly as <span class="math inline">\(\widehat{\mathbf{y}}_{-i} = \mathbf{X}
\mathbf{b}_{-i}\)</span>, where <span class="math inline">\(\mathbf{X}\)</span> is the model-matrix for all of
the cases, and <span class="math inline">\(\mathbf{b}_{-i}\)</span> is
the vector of least-squares coefficients for the selected model with the
<span class="math inline">\(i\)</span>th fold omitted.</p>
<p>Additionally, the command
<code>lm(y[-indices] ~ X[-indices, x.names.i] - 1)</code>, which is the
selected model with the <span class="math inline">\(i\)</span>th fold
deleted, produces awkward coefficient names like
<code>"X[-indices, x.names.i]Infant.Mortality"</code>. Purely for
aesthetic reasons, the command
<code>sub("X\\[-indices, x.names.i\\]", "", names(coefs))</code> fixes
these awkward names, removing the extraneous text,
<code>"X[-indices, x.names.i]"</code>.</p>
<p>Applying <code>selectSubsets()</code> to the full data produces the
full-data cross-validated RMSE (which we obtained previously):</p>
<div class="sourceCode" id="cb27"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">selectSubsets</span><span class="op">(</span>model<span class="op">=</span><span class="va">m.swiss</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 45.916</span></span>
<span><span class="co">#&gt; attr(,"casewise loss")</span></span>
<span><span class="co">#&gt; [1] "(y - yhat)^2"</span></span></code></pre></div>
<p>Similarly, applying the function to an imaginary “fold” of 5 cases
returns the RMSE for the cases in the fold, based on the model selected
and fit to the cases omitting the fold; the RMSE for all of the cases,
based on the same model; and the coefficients of the selected model,
which includes 4 or the 5 predictors (and the intercept):</p>
<div class="sourceCode" id="cb28"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">selectSubsets</span><span class="op">(</span>model<span class="op">=</span><span class="va">m.swiss</span>, indices<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/seq.html" class="external-link">seq</a></span><span class="op">(</span><span class="fl">5</span>, <span class="fl">45</span>, by<span class="op">=</span><span class="fl">10</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; $fit.i</span></span>
<span><span class="co">#&gt; [1] 62.922 67.001 73.157 83.778 32.251</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $crit.all.i</span></span>
<span><span class="co">#&gt; [1] 46.297</span></span>
<span><span class="co">#&gt; attr(,"casewise loss")</span></span>
<span><span class="co">#&gt; [1] "(y - yhat)^2"</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $coefficients</span></span>
<span><span class="co">#&gt;      (Intercept)      Agriculture        Education         Catholic </span></span>
<span><span class="co">#&gt;         63.80452         -0.15895         -1.04218          0.13066 </span></span>
<span><span class="co">#&gt; Infant.Mortality </span></span>
<span><span class="co">#&gt;          1.01895</span></span></code></pre></div>
<p>Then, using <code>selectSubsets()</code> in cross-validation, we
get:</p>
<div class="sourceCode" id="cb29"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="op">(</span><span class="va">cv.swiss</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/cvSelect.html">cvSelect</a></span><span class="op">(</span><span class="va">selectSubsets</span>, model<span class="op">=</span><span class="va">m.swiss</span>,</span>
<span>                      data<span class="op">=</span><span class="va">swiss</span>, seed<span class="op">=</span><span class="fl">8433</span><span class="op">)</span><span class="op">)</span> <span class="co"># use same folds</span></span>
<span><span class="co">#&gt; R RNG seed set to 8433</span></span>
<span><span class="co">#&gt; 10-Fold Cross Validation</span></span>
<span><span class="co">#&gt; cross-validation criterion = 65.835</span></span>
<span><span class="co">#&gt; bias-adjusted cross-validation criterion = 63.644</span></span>
<span><span class="co">#&gt; full-sample criterion = 45.916</span></span></code></pre></div>
<p>Cross-validation shows that model selection exacts a penalty in RMSE.
Examining the models selected for the 10 folds reveals that there is
some uncertainty in identifying the predictors in the “best” model, with
<code>Agriculture</code> sometimes appearing and sometimes not:</p>
<div class="sourceCode" id="cb30"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/cvSelect.html">compareFolds</a></span><span class="op">(</span><span class="va">cv.swiss</span><span class="op">)</span></span>
<span><span class="co">#&gt;         (Intercept) Catholic Education Infant.Mortality Agriculture</span></span>
<span><span class="co">#&gt; Fold 1      59.0852   0.1397   -1.0203           1.2985       -0.17</span></span>
<span><span class="co">#&gt; Fold 2      67.0335   0.1367   -1.0499           0.9413       -0.20</span></span>
<span><span class="co">#&gt; Fold 3      55.0453   0.1221   -0.8757           1.3541       -0.15</span></span>
<span><span class="co">#&gt; Fold 4      62.5543   0.1236   -0.9719           1.0679       -0.16</span></span>
<span><span class="co">#&gt; Fold 5      50.4643   0.1057   -0.7863           1.2144            </span></span>
<span><span class="co">#&gt; Fold 6      68.0289   0.1195   -1.0073           0.8294       -0.17</span></span>
<span><span class="co">#&gt; Fold 7      66.5219   0.1357   -1.0827           0.9523       -0.19</span></span>
<span><span class="co">#&gt; Fold 8      46.3507   0.0776   -0.7637           1.4463            </span></span>
<span><span class="co">#&gt; Fold 9      62.2632   0.1230   -1.0067           1.1000       -0.17</span></span>
<span><span class="co">#&gt; Fold 10     52.5112   0.1005   -0.7232           1.0809</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="appendix-why-the-complement-of-auc-isnt-a-casewise-cv-criterion">Appendix: Why the complement of AUC isn’t a casewise CV
criterion<a class="anchor" aria-label="anchor" href="#appendix-why-the-complement-of-auc-isnt-a-casewise-cv-criterion"></a>
</h2>
<p>Consider calculating AUC for folds in which a validation set contains
<span class="math inline">\(n_v\)</span> observations. To calculate AUC
in the validation set, we need the vector of prediction criteria, <span class="math inline">\(\widehat{\mathbf{y}}_{v_{(n_v \times 1)}} =
(\widehat{y}_1, ..., \widehat{y}_{n_v})^T\)</span>, and the vector of
observed responses in the validation set, <span class="math inline">\(\mathbf{y}_{v_{(n_v \times 1)}} = (y_1, \ldots,
y_{n_v})^T\)</span> with <span class="math inline">\(y_i \in \{0,1\}, \;
i = 1, \ldots, n_v\)</span>.</p>
<p>To construct the ROC curve, only the ordering of the values in <span class="math inline">\(\mathbf{\widehat{y}}_v\)</span> is relevant. Thus,
assuming that there are no ties, and reordering observations if
necessary, we can set <span class="math inline">\(\mathbf{\widehat{y}}_v
= (1, 2, \ldots, n_v)^T\)</span>.</p>
<p>If the AUC can be expressed as the casewise mean or sum of a function
<span class="math inline">\(\mathrm{cv}(\widehat{y}_i,y_i)\)</span>,
where <span class="math inline">\(\mathrm{cv}:
\{1,2,...,n_v\}\times\{0,1\} \rightarrow [0,1]\)</span>, then <span class="math display">\[\begin{equation}
\label{eq:cw}
\tag{1}
\sum_{i=1}^{n_v} \mathrm{cv}(\widehat{y}_i,y_i) =
\mathrm{AUC}(\mathbf{\widehat{y}}_v,\mathbf{y}_v)
\end{equation}\]</span> must hold for all <span class="math inline">\(2^{n_v}\)</span> possible values of <span class="math inline">\(\mathbf{y}_v = (y_1,...,y_{n_v})^T\)</span>. If
all <span class="math inline">\(y\mathrm{s}\)</span> have the same
value, either 1 or 0, then the definition of AUC is ambiguous. AUC could
be considered undefined, or it could be set to 0 if all <span class="math inline">\(y\)</span>s are 0 and to 1 if all <span class="math inline">\(y\)</span>s are 1. If AUC is considered to be
undefined in these cases, we have <span class="math inline">\(2^{n_v} -
2\)</span> admissible values for <span class="math inline">\(\mathbf{y}_v\)</span>.</p>
<p>Thus, equation (<span class="math inline">\(\ref{eq:cw}\)</span>)
produces either <span class="math inline">\(2^{n_v}\)</span> or <span class="math inline">\(2^{n_v}-2\)</span> constraints. Although there are
only <span class="math inline">\(2n_v\)</span> possible values for the
<span class="math inline">\(\mathrm{cv(\cdot)}\)</span> function,
equation (<span class="math inline">\(\ref{eq:cw}\)</span>) could,
nevertheless, have consistent solutions. We therefore need to determine
whether there is a value of <span class="math inline">\(n_v\)</span> for
which (<span class="math inline">\(\ref{eq:cw}\)</span>) has no
consistent solution for all admissible values of <span class="math inline">\(\mathbf{y}_v\)</span>. In that eventuality, we
will have shown that AUC cannot, in general, be expressed through a
casewise sum.</p>
<p>If <span class="math inline">\(n_v=3\)</span>, we show below that
(<span class="math inline">\(\ref{eq:cw}\)</span>) has no consistent
solution if we include all possibilities for <span class="math inline">\(\mathbf{y}_v\)</span>, but does if we exclude
cases where all <span class="math inline">\(y\)</span>s have the same
value. If <span class="math inline">\(n_v=4\)</span>, we show that there
are no consistent solutions in either case.</p>
<p>The following R function computes AUC from <span class="math inline">\(\mathbf{\widehat{y}}_v\)</span> and <span class="math inline">\(\mathbf{y}_v\)</span>, accommodating the cases
where <span class="math inline">\(\mathbf{y}_v\)</span> is all 0s or all
1s:</p>
<div class="sourceCode" id="cb31"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">AUC</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">y</span>, <span class="va">yhat</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html" class="external-link">seq_along</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">s</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span></span>
<span>  <span class="kw">if</span> <span class="op">(</span><span class="va">s</span> <span class="op">==</span> <span class="fl">0</span><span class="op">)</span> <span class="kw"><a href="https://rdrr.io/r/base/function.html" class="external-link">return</a></span><span class="op">(</span><span class="fl">0</span><span class="op">)</span></span>
<span>  <span class="kw">if</span> <span class="op">(</span><span class="va">s</span> <span class="op">==</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span><span class="op">)</span> <span class="kw"><a href="https://rdrr.io/r/base/function.html" class="external-link">return</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span></span>
<span>  <span class="fu">Metrics</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/Metrics/man/auc.html" class="external-link">auc</a></span><span class="op">(</span><span class="va">y</span>, <span class="va">yhat</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code></pre></div>
<p>We then define a function to generate all possible <span class="math inline">\(\mathbf{y}_v\)</span>s of length <span class="math inline">\(n_v\)</span> as rows of the matrix <span class="math inline">\(\mathbf{Y}_{(2^{n_v} \times n_v)}\)</span>:</p>
<div class="sourceCode" id="cb32"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">Ymat</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">n_v</span>, <span class="va">exclude_identical</span> <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/stopifnot.html" class="external-link">stopifnot</a></span><span class="op">(</span><span class="va">n_v</span> <span class="op">&gt;</span> <span class="fl">0</span> <span class="op">&amp;&amp;</span> <span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="va">n_v</span><span class="op">)</span> <span class="op">==</span> <span class="va">n_v</span><span class="op">)</span>    <span class="co"># n_v must be a positive integer</span></span>
<span>  <span class="va">ret</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html" class="external-link">sapply</a></span><span class="op">(</span><span class="fl">0</span><span class="op">:</span><span class="op">(</span><span class="fl">2</span><span class="op">^</span><span class="va">n_v</span> <span class="op">-</span> <span class="fl">1</span><span class="op">)</span>,</span>
<span>                <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/base/integer.html" class="external-link">as.integer</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rawConversion.html" class="external-link">intToBits</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span> <span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="va">n_v</span>, <span class="op">]</span></span>
<span>  <span class="va">ret</span> <span class="op">&lt;-</span> <span class="kw">if</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">is.matrix</a></span><span class="op">(</span><span class="va">ret</span><span class="op">)</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/base/t.html" class="external-link">t</a></span><span class="op">(</span><span class="va">ret</span><span class="op">)</span> <span class="kw">else</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="va">ret</span><span class="op">)</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/colnames.html" class="external-link">colnames</a></span><span class="op">(</span><span class="va">ret</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste0</a></span><span class="op">(</span><span class="st">"y"</span>, <span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">ncol</a></span><span class="op">(</span><span class="va">ret</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="kw">if</span> <span class="op">(</span><span class="va">exclude_identical</span><span class="op">)</span> <span class="va">ret</span><span class="op">[</span><span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">ret</span><span class="op">)</span><span class="op">)</span>, <span class="op">]</span> <span class="kw">else</span> <span class="va">ret</span></span>
<span><span class="op">}</span></span></code></pre></div>
<p>For <span class="math inline">\(n_v=3\)</span>,</p>
<div class="sourceCode" id="cb33"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">Ymat</span><span class="op">(</span><span class="fl">3</span><span class="op">)</span></span>
<span><span class="co">#&gt;      y1 y2 y3</span></span>
<span><span class="co">#&gt; [1,]  0  0  0</span></span>
<span><span class="co">#&gt; [2,]  1  0  0</span></span>
<span><span class="co">#&gt; [3,]  0  1  0</span></span>
<span><span class="co">#&gt; [4,]  1  1  0</span></span>
<span><span class="co">#&gt; [5,]  0  0  1</span></span>
<span><span class="co">#&gt; [6,]  1  0  1</span></span>
<span><span class="co">#&gt; [7,]  0  1  1</span></span>
<span><span class="co">#&gt; [8,]  1  1  1</span></span></code></pre></div>
<p>If we exclude <span class="math inline">\(\mathbf{y}_v\)</span>s with
identical values, then</p>
<div class="sourceCode" id="cb34"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">Ymat</span><span class="op">(</span><span class="fl">3</span>, exclude_identical <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="co">#&gt;      y1 y2 y3</span></span>
<span><span class="co">#&gt; [1,]  1  0  0</span></span>
<span><span class="co">#&gt; [2,]  0  1  0</span></span>
<span><span class="co">#&gt; [3,]  1  1  0</span></span>
<span><span class="co">#&gt; [4,]  0  0  1</span></span>
<span><span class="co">#&gt; [5,]  1  0  1</span></span>
<span><span class="co">#&gt; [6,]  0  1  1</span></span></code></pre></div>
<p>Here is <span class="math inline">\(\mathbf{Y}\)</span> with
corresponding values of AUC:</p>
<div class="sourceCode" id="cb35"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span><span class="fu">Ymat</span><span class="op">(</span><span class="fl">3</span><span class="op">)</span>, AUC <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html" class="external-link">apply</a></span><span class="op">(</span><span class="fu">Ymat</span><span class="op">(</span><span class="fl">3</span><span class="op">)</span>, <span class="fl">1</span>, <span class="va">AUC</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt;      y1 y2 y3 AUC</span></span>
<span><span class="co">#&gt; [1,]  0  0  0 0.0</span></span>
<span><span class="co">#&gt; [2,]  1  0  0 0.0</span></span>
<span><span class="co">#&gt; [3,]  0  1  0 0.5</span></span>
<span><span class="co">#&gt; [4,]  1  1  0 0.0</span></span>
<span><span class="co">#&gt; [5,]  0  0  1 1.0</span></span>
<span><span class="co">#&gt; [6,]  1  0  1 0.5</span></span>
<span><span class="co">#&gt; [7,]  0  1  1 1.0</span></span>
<span><span class="co">#&gt; [8,]  1  1  1 1.0</span></span></code></pre></div>
<p>The values of <span class="math inline">\(\mathrm{cv}(\widehat{y}_i,
y_i)\)</span> that express AUC as a sum of casewise values are solutions
of equation (<span class="math inline">\(\ref{eq:cw}\)</span>), which
can be written as solutions of the following system of <span class="math inline">\(2^{n_v}\)</span> linear simultaneous equations in
<span class="math inline">\(2n_v\)</span> unknowns: <span class="math display">\[\begin{equation}
\label{eq:lin}
\tag{2}
(\mathbf{U} -\mathbf{Y}) \mathbf{c}_0 + \mathbf{Y} \mathbf{c}_1
=
[\mathbf{U} -\mathbf{Y}, \mathbf{Y}]
\begin{bmatrix}
\mathbf{c}_0 \\ \mathbf{c}_1
\end{bmatrix}
= \mathrm{AUC}(\mathbf{\widehat{Y}},\mathbf{Y})
\end{equation}\]</span> where <span class="math inline">\(\mathbf{U}_{(2^{n_v} \times n_v)}\)</span> is a
matrix of 1s conformable with <span class="math inline">\(\mathbf{Y}\)</span>; <span class="math inline">\(\mathbf{c}_0 = [\mathrm{cv}(1,0), c(2,0), ...,
\mathrm{cv}(n_v,0)]^T\)</span>; <span class="math inline">\(\mathbf{c}_1
= [\mathrm{cv}(1,1), c(2,1), ..., \mathrm{cv}(n_v,1)]^T\)</span>; <span class="math inline">\([\mathbf{U} -\mathbf{Y}, \mathbf{Y}]_{(2^{n_v}
\times 2n_v)}\)</span> and <span class="math inline">\(\begin{bmatrix}\begin{aligned} \mathbf{c}_0 \\
\mathbf{c}_1 \end{aligned} \end{bmatrix}_{(2n_v \times 1)}\)</span> are
partitioned matrices; and <span class="math inline">\(\mathbf{\widehat{Y}}_{(2^{n_v} \times
n_v)}\)</span> is a matrix each of whose rows consists of the integers 1
to <span class="math inline">\(n_v\)</span>.</p>
<p>We can test whether equation (<span class="math inline">\(\ref{eq:lin}\)</span>) has a solution for any
given <span class="math inline">\(n_v\)</span> by trying to solve it as
a least-squares problem, considering whether the residuals of the
associated linear model are all 0, using the “design matrix” <span class="math inline">\([\mathbf{U} -\mathbf{Y}, \mathbf{Y}]\)</span> to
predict the “outcome” <span class="math inline">\(\mathrm{AUC}(\mathbf{\widehat{Y}},\mathbf{Y})_{(2^{n_v}
\times 1)}\)</span>:</p>
<div class="sourceCode" id="cb36"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">resids</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">n_v</span>, <span class="va">exclude_identical</span> <span class="op">=</span> <span class="cn">FALSE</span>, </span>
<span>                   <span class="va">tol</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html" class="external-link">sqrt</a></span><span class="op">(</span><span class="va">.Machine</span><span class="op">$</span><span class="va">double.eps</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">Y</span> <span class="op">&lt;-</span> <span class="fu">Ymat</span><span class="op">(</span><span class="va">n_v</span>, exclude_identical <span class="op">=</span> <span class="va">exclude_identical</span><span class="op">)</span></span>
<span>  <span class="va">AUC</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html" class="external-link">apply</a></span><span class="op">(</span><span class="va">Y</span>, <span class="fl">1</span>, <span class="va">AUC</span><span class="op">)</span></span>
<span>  <span class="va">X</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span><span class="fl">1</span><span class="op">-</span><span class="va">Y</span>, <span class="va">Y</span><span class="op">)</span></span>
<span>  <span class="va">opts</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/options.html" class="external-link">options</a></span><span class="op">(</span>warn <span class="op">=</span> <span class="op">-</span><span class="fl">1</span><span class="op">)</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/on.exit.html" class="external-link">on.exit</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/options.html" class="external-link">options</a></span><span class="op">(</span><span class="va">opts</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="va">fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lsfit.html" class="external-link">lsfit</a></span><span class="op">(</span><span class="va">X</span>, <span class="va">AUC</span>, intercept <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span>  <span class="va">ret</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">max</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html" class="external-link">abs</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/residuals.html" class="external-link">residuals</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="kw">if</span><span class="op">(</span><span class="va">ret</span> <span class="op">&lt;</span> <span class="va">tol</span><span class="op">)</span><span class="op">{</span></span>
<span>    <span class="va">ret</span> <span class="op">&lt;-</span> <span class="fl">0</span></span>
<span>    <span class="va">solution</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/coef.html" class="external-link">coef</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/names.html" class="external-link">names</a></span><span class="op">(</span><span class="va">solution</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste0</a></span><span class="op">(</span><span class="st">"c("</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="va">n_v</span>, <span class="fl">1</span><span class="op">:</span><span class="va">n_v</span><span class="op">)</span>, <span class="st">","</span>, </span>
<span>                              <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span><span class="op">:</span><span class="fl">1</span>, each <span class="op">=</span> <span class="va">n_v</span><span class="op">)</span>, <span class="st">")"</span><span class="op">)</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/attr.html" class="external-link">attr</a></span><span class="op">(</span><span class="va">ret</span>, <span class="st">"solution"</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/zapsmall.html" class="external-link">zapsmall</a></span><span class="op">(</span><span class="va">solution</span><span class="op">)</span></span>
<span>  <span class="op">}</span></span>
<span>  <span class="va">ret</span></span>
<span><span class="op">}</span></span></code></pre></div>
<p>The case <span class="math inline">\(n_v=3\)</span>, excluding
identical <span class="math inline">\(y\)</span>s, has a solution:</p>
<div class="sourceCode" id="cb37"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">resids</span><span class="op">(</span><span class="fl">3</span>, exclude_identical <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 0</span></span>
<span><span class="co">#&gt; attr(,"solution")</span></span>
<span><span class="co">#&gt; c(1,0) c(2,0) c(3,0) c(1,1) c(2,1) c(3,1) </span></span>
<span><span class="co">#&gt;    1.0    0.0   -0.5    0.5    0.0    0.0</span></span></code></pre></div>
<p>But, if identical <span class="math inline">\(y\)</span>s are
included, the equation is not consistent:</p>
<div class="sourceCode" id="cb38"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">resids</span><span class="op">(</span><span class="fl">3</span>, exclude_identical <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 0.125</span></span></code></pre></div>
<p>For <span class="math inline">\(n_v=4\)</span>, there are no
solutions in either case:</p>
<div class="sourceCode" id="cb39"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">resids</span><span class="op">(</span><span class="fl">4</span>, exclude_identical <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 0.083333</span></span>
<span><span class="fu">resids</span><span class="op">(</span><span class="fl">4</span>, exclude_identical <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 0.25</span></span></code></pre></div>
<p>Consequently, the widely employed AUC measure of fit for binary
regression cannot in general be used for a casewise cross-validation
criterion.</p>
</div>
<div class="section level2 unnumbered">
<h2 class="unnumbered" id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<div id="refs" class="references csl-bib-body hanging-indent" line-spacing="2">
<div id="ref-Fox:2016" class="csl-entry">
Fox, J. (2016). <em>Applied regression analysis and generalized linear
models</em> (Second edition). Thousand Oaks <span>CA</span>: Sage.
</div>
<div id="ref-FoxWeisberg:2019" class="csl-entry">
Fox, J., &amp; Weisberg, S. (2019). <em>An <span>R</span> companion to
applied regression</em> (Third edition). Thousand Oaks <span>CA</span>:
Sage.
</div>
<div id="ref-HamnerFrasco:2018" class="csl-entry">
Hamner, B., &amp; Frasco, M. (2018). <em>Metrics: Evaluation metrics for
machine learning</em>. Retrieved from <a href="https://CRAN.R-project.org/package=Metrics" class="external-link">https://CRAN.R-project.org/package=Metrics</a>
</div>
<div id="ref-LudeckeWaggonerMakowski:2019" class="csl-entry">
Lüdecke, D., Waggoner, P., &amp; Makowski, D. (2019). <span class="nocase">insight</span>: A unified interface to access information
from model objects in <span>R</span>. <em>Journal of Open Source
Software</em>, <em>4</em>(38), 1412.
</div>
<div id="ref-LumleyMiller:2020" class="csl-entry">
Lumley, T., &amp; Miller, A. (2020). <em><span class="nocase">leaps</span>: Regression subset selection</em>. Retrieved
from <a href="https://CRAN.R-project.org/package=leaps" class="external-link">https://CRAN.R-project.org/package=leaps</a>
</div>
<div id="ref-Wikipedia-ROC:2023" class="csl-entry">
"Receiver operating characteristic". (2023). Receiver operating
characteristic—<span>W</span>ikipedia<span>,</span> the free
encyclopedia. Retrieved from <a href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic" class="external-link">https://en.wikipedia.org/wiki/Receiver_operating_characteristic</a>
</div>
<div id="ref-VenablesRipley:2002" class="csl-entry">
Venables, W. N., &amp; Ripley, B. D. (2002). <em>Modern applied
statistics with <span>S</span></em> (Fourth edition). New York:
Springer.
</div>
</div>
</div>

  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by John Fox, Georges Monette.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
