\relax 
\bibstyle{jss}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{JamesEtAl:2021}
\citation{ArlotCelisse:2010}
\citation{Harrell:2015}
\newlabel{cross-validation}{{1}{1}{}{section.1}{}}
\citation{JamesEtAl:2021}
\citation{JamesEtAl:2021}
\citation{JamesEtAl:2021}
\citation{CantyRipley2022,DavisonHinkley:1997}
\newlabel{examples}{{2}{2}{}{section.2}{}}
\newlabel{polynomial-regression-for-the-auto-data}{{2.1}{2}{}{subsection.2.1}{}}
\citation{JamesEtAl:2021}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces `mpg` vs `horsepower` for the `Auto` data}}{4}{figure.1}\protected@file@percent }
\newlabel{fig:mpg-horsepower-scatterplot}{{1}{4}{`mpg` vs `horsepower` for the `Auto` data}{figure.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces `mpg` vs `horsepower` for the `Auto` data}}{5}{figure.2}\protected@file@percent }
\newlabel{fig:mpg-horsepower-scatterplot-polynomials}{{2}{5}{`mpg` vs `horsepower` for the `Auto` data}{figure.2}{}}
\newlabel{using-cv}{{2.1.1}{6}{}{subsubsection.2.1.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Estimated squared error as a function of polynomial degree, $p$}}{7}{figure.3}\protected@file@percent }
\newlabel{fig:mpg-horsepower-MSE-se}{{3}{7}{Estimated squared error as a function of polynomial degree, $p$}{figure.3}{}}
\citation{Mersmann:2023}
\newlabel{comparing-competing-models}{{2.1.2}{9}{}{subsubsection.2.1.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Cross-validated 10-fold and LOO MSE as a function of polynomial degree, $p$}}{12}{figure.4}\protected@file@percent }
\newlabel{fig:polynomial-regression-CV-graph}{{4}{12}{Cross-validated 10-fold and LOO MSE as a function of polynomial degree, $p$}{figure.4}{}}
\citation{FoxWeisberg:2019}
\citation{FoxWeisberg:2019}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Cross-validated 10-fold and LOO MSE as a function of polynomial degree, $p$}}{13}{figure.5}\protected@file@percent }
\newlabel{fig:polynomial-regression-CV-graph-2}{{5}{13}{Cross-validated 10-fold and LOO MSE as a function of polynomial degree, $p$}{figure.5}{}}
\newlabel{logistic-regression-for-the-mroz-data}{{2.2}{13}{}{subsection.2.2}{}}
\citation{FoxWeisberg:2019}
\citation{DavisonHinkley:1997}
\citation{BatesHastieTibshirani:2023}
\citation{ArlotCelisse:2010}
\citation{BatesHastieTibshirani:2023}
\citation{Vehtari:2023}
\newlabel{cross-validating-mixed-effects-models}{{3}{17}{}{section.3}{}}
\citation{RaudenbushBryk:2002}
\citation{FoxWeisberg:2019}
\citation{PinheiroBates:2000}
\newlabel{example-the-high-school-and-beyond-data}{{3.1}{18}{}{subsection.3.1}{}}
\citation{WickhamEtAl:2023}
\citation{FoxWeisberg:2019}
\citation{BatesEtAl:2015}
\newlabel{example-contrived-hierarchical-data}{{3.2}{23}{}{subsection.3.2}{}}
\citation{Sarkar:2008}
\citation{SarkarAndrews:2022}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Hierarchical data set, showing the first 10 of 100 students}}{25}{figure.6}\protected@file@percent }
\newlabel{fig:plot1}{{6}{25}{Hierarchical data set, showing the first 10 of 100 students}{figure.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Predictions from the random intercept model}}{29}{figure.7}\protected@file@percent }
\newlabel{fig:plot-fits-mod0}{{7}{29}{Predictions from the random intercept model}{figure.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Predictions from the model with random intercepts and $x$ as a fixed-effect predictor}}{31}{figure.8}\protected@file@percent }
\newlabel{fig:plot-fits-mod1}{{8}{31}{Predictions from the model with random intercepts and $x$ as a fixed-effect predictor}{figure.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Predictors from the model with random intercepts, $x$, and the group (student) mean of $x$ as predictors}}{33}{figure.9}\protected@file@percent }
\newlabel{fig:plot-fits-mod2}{{9}{33}{Predictors from the model with random intercepts, $x$, and the group (student) mean of $x$ as predictors}{figure.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Predictions from the estimated model generating the data}}{35}{figure.10}\protected@file@percent }
\newlabel{fig:plot-fits-mod3}{{10}{35}{Predictions from the estimated model generating the data}{figure.10}{}}
\citation{DiggleLiangZeger:1994}
\newlabel{example-crossed-random-effects}{{3.3}{36}{}{subsection.3.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces 10-fold cluster-based cross-validation comparing random intercept models with varying fixed effects}}{37}{figure.11}\protected@file@percent }
\newlabel{fig:cross-validation-clusters}{{11}{37}{10-fold cluster-based cross-validation comparing random intercept models with varying fixed effects}{figure.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces 10-fold case-based cross-validation comparing random intercept models with varying fixed effects}}{38}{figure.12}\protected@file@percent }
\newlabel{fig:cross-validation-cases}{{12}{38}{10-fold case-based cross-validation comparing random intercept models with varying fixed effects}{figure.12}{}}
\citation{DiggleLiangZeger:1994}
\citation{Stata:2023}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Growth trajectories for 48 pigs, with overall least-squares line (sold blue) and loess line (broken magenta)}}{40}{figure.13}\protected@file@percent }
\newlabel{fig:pigs-graph}{{13}{40}{Growth trajectories for 48 pigs, with overall least-squares line (sold blue) and loess line (broken magenta)}{figure.13}{}}
\newlabel{replicating-cross-validation}{{4}{43}{}{section.4}{}}
\citation{HastieTibshiraniFriedman:2009}
\citation{HastieTibshiraniFriedman:2009}
\newlabel{cross-validating-model-selection}{{5}{45}{}{section.5}{}}
\newlabel{a-preliminary-example}{{5.1}{45}{}{subsection.5.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces  Replicated cross-validated 10-fold CV as a function of polynomial degree, $p$}}{46}{figure.14}\protected@file@percent }
\newlabel{fig:model-comparison-with-reps}{{14}{46}{Replicated cross-validated 10-fold CV as a function of polynomial degree, $p$}{figure.14}{}}
\citation{VenablesRipley:2002}
\newlabel{mrozs-logistic-regression-revisited}{{5.2}{51}{}{subsection.5.2}{}}
\citation{Weisberg:2014}
\citation{FoxWeisberg:2019}
\newlabel{cross-validating-choice-of-transformations-in-regression}{{5.3}{54}{}{subsection.5.3}{}}
\citation{BoxCox:1964}
\citation{Weisberg:2014}
\citation{FoxWeisberg:2019}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Scatterplot matrix for the `Prestige` data}}{56}{figure.15}\protected@file@percent }
\newlabel{fig:scatterplot-matrix}{{15}{56}{Scatterplot matrix for the `Prestige` data}{figure.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Scatterplot matrix for the `Prestige` data with the predictors transformed}}{58}{figure.16}\protected@file@percent }
\newlabel{fig:transformed-predictors}{{16}{58}{Scatterplot matrix for the `Prestige` data with the predictors transformed}{figure.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Component+residual plots for the `Prestige` regression with the original predictors}}{59}{figure.17}\protected@file@percent }
\newlabel{fig:CR-plots-untransformed}{{17}{59}{Component+residual plots for the `Prestige` regression with the original predictors}{figure.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces Component+residual plots for the `Prestige` regression with transformed predictors}}{60}{figure.18}\protected@file@percent }
\newlabel{fig:CR-plots-transformed}{{18}{60}{Component+residual plots for the `Prestige` regression with transformed predictors}{figure.18}{}}
\citation{HastieTibshiraniFriedman:2009}
\newlabel{selecting-both-transformations-and-predictorsvenables}{{5.4}{62}{}{subsection.5.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces Scatterplot matrix for the numeric variables in the `Auto` data}}{64}{figure.19}\protected@file@percent }
\newlabel{fig:Auto-explore}{{19}{64}{Scatterplot matrix for the numeric variables in the `Auto` data}{figure.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces Component+residual plots for the working model fit to the `Auto` data}}{67}{figure.20}\protected@file@percent }
\newlabel{fig:Auto-working-model}{{20}{67}{Component+residual plots for the working model fit to the `Auto` data}{figure.20}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces Scatterplot matrix for the transformed numeric variables in the `Auto` data}}{71}{figure.21}\protected@file@percent }
\newlabel{fig:Auto-transformed-scatterplot-matrix}{{21}{71}{Scatterplot matrix for the transformed numeric variables in the `Auto` data}{figure.21}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces Component+residual plots for the model fit to the transformed `Auto` data}}{72}{figure.22}\protected@file@percent }
\newlabel{fig:Auto-CR-plots-transformed}{{22}{72}{Component+residual plots for the model fit to the transformed `Auto` data}{figure.22}{}}
\newlabel{parallel-computations}{{6}{76}{}{section.6}{}}
\citation{Wikipedia-ROC:2023}
\citation{HamnerFrasco:2018}
\citation{FoxWeisberg:2019}
\newlabel{extending-the-cv-package}{{7}{77}{}{section.7}{}}
\newlabel{adding-a-cost-criterion}{{7.1}{77}{}{subsection.7.1}{}}
\citation{VenablesRipley:2002}
\citation{Fox:2016}
\newlabel{adding-a-model-class-not-covered-by-the-default-cv-method}{{7.2}{79}{}{subsection.7.2}{}}
\newlabel{independently-sampled-cases}{{7.2.1}{79}{}{subsubsection.7.2.1}{}}
\citation{FoxWeisberg:2019}
\citation{FoxWeisberg:2019}
\citation{LudeckeWaggonerMakowski:2019}
\newlabel{mixed-effects-models}{{7.2.2}{84}{}{subsubsection.7.2.2}{}}
\citation{VenablesRipley:2002}
\citation{VenablesRipley:2002}
\citation{LumleyMiller:2020}
\newlabel{adding-a-model-selection-procedure}{{7.3}{90}{}{subsection.7.3}{}}
\citation{LumleyMiller:2020}
\@writefile{lof}{\contentsline {figure}{\numberline {23}{\ignorespaces Selecting the best model of each size}}{93}{figure.23}\protected@file@percent }
\newlabel{fig:subset-selection}{{23}{93}{Selecting the best model of each size}{figure.23}{}}
\citation{Fox:2016}
\citation{Wikipedia-Woodbury:2023}
\newlabel{computational-notes}{{8}{96}{}{section.8}{}}
\newlabel{efficient-computations-for-linear-and-generalized-linear-models}{{8.1}{96}{}{subsection.8.1}{}}
\citation{FoxWeisberg:2019}
\citation{ArlotCelisse:2010}
\newlabel{computation-of-the-bias-corrected-cv-criterion-and-confidence-intervals}{{8.2}{97}{}{subsection.8.2}{}}
\citation{DavisonHinkley:1997}
\citation{BatesHastieTibshirani:2023}
\newlabel{why-the-complement-of-auc-isnt-a-casewise-cv-criterion}{{9}{98}{}{section.9}{}}
\newlabel{eq:cw}{{{1}}{99}{}{AMS.1}{}}
\newlabel{eq:lin}{{{2}}{100}{}{AMS.2}{}}
\bibdata{cv.bib}
\bibcite{ArlotCelisse:2010}{{1}{2010}{{Arlot and Celisse}}{{}}}
\bibcite{BatesEtAl:2015}{{2}{2015}{{Bates \emph  {et~al.}}}{{Bates, M{\"a}chler, Bolker, and Walker}}}
\bibcite{BatesHastieTibshirani:2023}{{3}{2023}{{Bates \emph  {et~al.}}}{{Bates, Hastie, and Tibshirani}}}
\bibcite{BoxCox:1964}{{4}{1964}{{Box and Cox}}{{}}}
\bibcite{CantyRipley2022}{{5}{2022}{{Canty and Ripley}}{{}}}
\bibcite{DavisonHinkley:1997}{{6}{1997}{{Davison and Hinkley}}{{}}}
\bibcite{DiggleLiangZeger:1994}{{7}{1994}{{Diggle \emph  {et~al.}}}{{Diggle, Liang, and Zeger}}}
\bibcite{Fox:2016}{{8}{2016}{{Fox}}{{}}}
\bibcite{FoxWeisberg:2019}{{9}{2019}{{Fox and Weisberg}}{{}}}
\bibcite{HamnerFrasco:2018}{{10}{2018}{{Hamner and Frasco}}{{}}}
\bibcite{Harrell:2015}{{11}{2015}{{Harrell}}{{}}}
\bibcite{HastieTibshiraniFriedman:2009}{{12}{2009}{{Hastie \emph  {et~al.}}}{{Hastie, Tibshirani, and Friedman}}}
\bibcite{JamesEtAl:2021}{{13}{2021}{{James \emph  {et~al.}}}{{James, Witten, Hastie, and Tibshirani}}}
\bibcite{LumleyMiller:2020}{{14}{2020}{{Lumley and Miller}}{{}}}
\bibcite{LudeckeWaggonerMakowski:2019}{{15}{2019}{{Lüdecke \emph  {et~al.}}}{{Lüdecke, Waggoner, and Makowski}}}
\bibcite{Mersmann:2023}{{16}{2023}{{Mersmann}}{{}}}
\bibcite{PinheiroBates:2000}{{17}{2000}{{Pinheiro and Bates}}{{}}}
\bibcite{RaudenbushBryk:2002}{{18}{2002}{{Raudenbush and Bryk}}{{}}}
\bibcite{Wikipedia-ROC:2023}{{19}{2023}{{"Receiver operating characteristic"}}{{}}}
\bibcite{Sarkar:2008}{{20}{2008}{{Sarkar}}{{}}}
\bibcite{SarkarAndrews:2022}{{21}{2022}{{Sarkar and Andrews}}{{}}}
\bibcite{Stata:2023}{{22}{2023}{{StataCorp LLC}}{{}}}
\bibcite{Vehtari:2023}{{23}{2023}{{Vehtari}}{{}}}
\bibcite{VenablesRipley:2002}{{24}{2002}{{Venables and Ripley}}{{}}}
\bibcite{Weisberg:2014}{{25}{2014}{{Weisberg}}{{}}}
\bibcite{WickhamEtAl:2023}{{26}{2023}{{Wickham \emph  {et~al.}}}{{Wickham, François, Henry, Müller, and Vaughan}}}
\bibcite{Wikipedia-Woodbury:2023}{{27}{2023}{{"Woodbury matrix identity"}}{{}}}
\gdef \@abspage@last{103}
